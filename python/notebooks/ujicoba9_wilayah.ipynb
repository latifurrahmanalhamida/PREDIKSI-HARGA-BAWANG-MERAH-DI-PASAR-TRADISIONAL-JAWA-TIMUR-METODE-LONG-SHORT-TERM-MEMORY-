{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009b34c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data: E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Banyuwangi.xlsx\n",
      "✓ Jumlah baris asli (raw): 1043\n",
      "✓ Sampel window: 953 (window=90)\n",
      "✓ Data ternormalisasi (0-1).\n",
      "[Info] Total: 953 | Train: 762 | Val: 77 | Test: 191\n",
      "   -> Selesai epoch : 50\n",
      "   -> Best epoch    : 50 (val_loss=0.000698)\n",
      "   -> Last loss     : 0.000901 | Last val_loss : 0.000698\n",
      "   -> MAPE          : 3.0860%\n",
      "   ✓ Plot disimpan: E:\\SKRIPSI 2025\\dataset\\DATASET TRAINING\\Banyuwangi_w90_e50_b64\\Banyuwangi_Plot.png\n",
      "   ✓ Prediksi disimpan: E:\\SKRIPSI 2025\\dataset\\DATASET TRAINING\\Banyuwangi_w90_e50_b64\\Banyuwangi_Prediksi_W90_E50_B64.xlsx\n",
      "   ✓ Ringkasan disimpan: E:\\SKRIPSI 2025\\dataset\\DATASET TRAINING\\Banyuwangi_w90_e50_b64\\Banyuwangi_Summary_W90_E50_B64.xlsx\n",
      "\n",
      "Selesai untuk file ini.\n"
     ]
    }
   ],
   "source": [
    "#SESUAI KONFIG TERBAIK DIBAB 3 \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# ============ SEEDS ============\n",
    "def reset_seeds():\n",
    "    np.random.seed(42)\n",
    "    python_random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "reset_seeds()\n",
    "\n",
    "# ============ KONFIG TETAP (HASIL TERBAIK) ============\n",
    "FIXED_WINDOW_SIZE = 90\n",
    "FIXED_EPOCH = 50\n",
    "FIXED_BATCH_SIZE = 64\n",
    "VAL_RATIO = 0.1\n",
    "\n",
    "# ============ PATH FILE (GANTI PER WILAYAH) ============\n",
    "path_file_input = r\"E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Banyuwangi.xlsx\"\n",
    "output_root = r\"E:\\SKRIPSI 2025\\dataset\\DATASET TRAINING\"\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "# ============ UTIL ============\n",
    "def create_sliding_window(dataset, window_size):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - window_size):\n",
    "        X.append(dataset[i:(i + window_size), 0])\n",
    "        Y.append(dataset[i + window_size, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def build_model_lstm(input_shape):\n",
    "    tf.random.set_seed(42)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.02))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(0.02))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# ============ LOAD DATA (SATU EXCEL) ============\n",
    "if not os.path.exists(path_file_input):\n",
    "    raise FileNotFoundError(f\"File tidak ditemukan: {path_file_input}\")\n",
    "\n",
    "df = pd.read_excel(path_file_input)\n",
    "if 'Harga (Rp)' not in df.columns:\n",
    "    raise KeyError(f\"Kolom 'Harga (Rp)' tidak ditemukan di file {path_file_input}\")\n",
    "\n",
    "raw_data = df['Harga (Rp)'].values.reshape(-1, 1)\n",
    "print(f\"✓ Data: {path_file_input}\")\n",
    "print(f\"✓ Jumlah baris asli (raw): {len(raw_data)}\")\n",
    "\n",
    "region_name = os.path.basename(path_file_input).replace(\"Data_Clean_\", \"\").replace(\".xlsx\", \"\")\n",
    "\n",
    "# ============ WINDOW DI SKALA ASLI ============\n",
    "X_full_raw, Y_full_raw = create_sliding_window(raw_data, FIXED_WINDOW_SIZE)\n",
    "print(f\"✓ Sampel window: {len(X_full_raw)} (window={FIXED_WINDOW_SIZE})\")\n",
    "train_size = int(len(X_full_raw) * 0.8)\n",
    "y_test_orig = Y_full_raw[train_size:]  # uji di skala asli\n",
    "\n",
    "# ============ SCALER FIT HANYA TRAIN (ANTI-LEAKAGE) ============\n",
    "raw_train_segment = raw_data[:train_size + FIXED_WINDOW_SIZE]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(raw_train_segment)\n",
    "scaled_data = scaler.transform(raw_data)\n",
    "print(\"✓ Data ternormalisasi (0-1).\")\n",
    "\n",
    "# ============ WINDOWING PADA DATA SCALED ============\n",
    "X_full_scaled, Y_full_scaled = create_sliding_window(scaled_data, FIXED_WINDOW_SIZE)\n",
    "X_full_scaled = X_full_scaled.reshape(X_full_scaled.shape[0], X_full_scaled.shape[1], 1)\n",
    "\n",
    "X_train_all, X_test = X_full_scaled[:train_size], X_full_scaled[train_size:]\n",
    "y_train_all = Y_full_scaled[:train_size]\n",
    "\n",
    "# Validasi tail dari TRAIN\n",
    "val_cut = int(len(X_train_all) * (1 - VAL_RATIO))\n",
    "X_train, X_val = X_train_all[:val_cut], X_train_all[val_cut:]\n",
    "y_train, y_val = y_train_all[:val_cut], y_train_all[val_cut:]\n",
    "\n",
    "print(f\"[Info] Total: {len(X_full_scaled)} | Train: {len(X_train_all)} | Val: {len(X_val)} | Test: {len(X_test)}\")\n",
    "\n",
    "# ============ TRAINING DENGAN KONFIG TETAP ============\n",
    "reset_seeds()\n",
    "model = build_model_lstm((X_train.shape[1], 1))\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=FIXED_EPOCH,\n",
    "    batch_size=FIXED_BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=0,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history.get('val_loss', None)\n",
    "last_loss = float(train_loss[-1])\n",
    "last_val_loss = float(val_loss[-1]) if val_loss is not None else None\n",
    "best_epoch = int(np.argmin(val_loss) + 1) if val_loss is not None else int(np.argmin(train_loss) + 1)\n",
    "best_val = float(np.min(val_loss)) if val_loss is not None else float(np.min(train_loss))\n",
    "\n",
    "print(f\"   -> Selesai epoch : {FIXED_EPOCH}\")\n",
    "print(f\"   -> Best epoch    : {best_epoch} (val_loss={best_val:.6f})\")\n",
    "print(f\"   -> Last loss     : {last_loss:.6f}\" + (f\" | Last val_loss : {last_val_loss:.6f}\" if last_val_loss is not None else \"\"))\n",
    "\n",
    "# ============ EVALUASI DI TEST (DENORMALIZED) ============\n",
    "predictions_scaled = model.predict(X_test, verbose=0)\n",
    "predictions_real = scaler.inverse_transform(predictions_scaled)\n",
    "mape = mean_absolute_percentage_error(y_test_orig.ravel(), predictions_real.ravel()) * 100\n",
    "print(f\"   -> MAPE          : {mape:.4f}%\")\n",
    "\n",
    "# ============ OUTPUT ============\n",
    "region_out_dir = os.path.join(output_root, f\"{region_name}_w{FIXED_WINDOW_SIZE}_e{FIXED_EPOCH}_b{FIXED_BATCH_SIZE}\")\n",
    "os.makedirs(region_out_dir, exist_ok=True)\n",
    "\n",
    "# Plot Actual vs Predicted\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(y_test_orig, label='Actual (Real Data)')\n",
    "plt.plot(predictions_real, label='Predicted (Denormalized)')\n",
    "plt.title(f'{region_name} | W{FIXED_WINDOW_SIZE} E{FIXED_EPOCH} B{FIXED_BATCH_SIZE}')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Harga')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plot_path = os.path.join(region_out_dir, f\"{region_name}_Plot.png\")\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"   ✓ Plot disimpan: {plot_path}\")\n",
    "\n",
    "# Excel per-baris\n",
    "y_test_safe = np.where(y_test_orig.flatten() == 0, np.finfo(float).eps, y_test_orig.flatten())\n",
    "err_pct = np.abs((y_test_orig.flatten() - predictions_real.flatten()) / y_test_safe) * 100\n",
    "out_df = pd.DataFrame({\n",
    "    'Actual (Real)': y_test_orig.flatten(),\n",
    "    'Predicted (Real)': predictions_real.flatten(),\n",
    "    'Selisih': (y_test_orig.flatten() - predictions_real.flatten()),\n",
    "    'Error (%)': err_pct\n",
    "})\n",
    "excel_path = os.path.join(region_out_dir, f\"{region_name}_Prediksi_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "out_df.to_excel(excel_path, index=False)\n",
    "print(f\"   ✓ Prediksi disimpan: {excel_path}\")\n",
    "\n",
    "# Ringkasan singkat\n",
    "summary = pd.DataFrame([{\n",
    "    'Region': region_name,\n",
    "    'Window Size': int(FIXED_WINDOW_SIZE),\n",
    "    'Epoch': int(FIXED_EPOCH),\n",
    "    'Batch Size': int(FIXED_BATCH_SIZE),\n",
    "    'Best Epoch (val)': int(best_epoch),\n",
    "    'Best Val Loss': float(best_val),\n",
    "    'Last Loss': float(last_loss),\n",
    "    'Last Val Loss': float(last_val_loss) if last_val_loss is not None else None,\n",
    "    'MAPE (%)': float(mape)\n",
    "}])\n",
    "summary_path = os.path.join(region_out_dir, f\"{region_name}_Summary_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "summary.to_excel(summary_path, index=False)\n",
    "print(f\"   ✓ Ringkasan disimpan: {summary_path}\")\n",
    "\n",
    "print(\"\\nSelesai untuk file ini.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5930f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data: E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Banyuwangi.xlsx\n",
      "✓ Jumlah baris asli (raw): 1043\n",
      "✓ Sampel window: 953 (window=90)\n",
      "✓ Data ternormalisasi (0-1).\n",
      "[Info] Total: 953 | Train: 762 | Val: 77 | Test: 191\n",
      "   -> Selesai epoch : 114\n",
      "   -> Best epoch    : 114 (val_loss=0.000409)\n",
      "   -> Last loss     : 0.000656 | Last val_loss : 0.000409\n",
      "   -> MAPE          : 2.8492%\n",
      "   ✓ Plot disimpan: E:\\SKRIPSI 2025\\dataset\\Banyuwangi_w90_e114_b64\\Banyuwangi_Plot.png\n",
      "   ✓ Prediksi disimpan: E:\\SKRIPSI 2025\\dataset\\Banyuwangi_w90_e114_b64\\Banyuwangi_Prediksi_W90_E114_B64.xlsx\n",
      "   ✓ Ringkasan disimpan: E:\\SKRIPSI 2025\\dataset\\Banyuwangi_w90_e114_b64\\Banyuwangi_Summary_W90_E114_B64.xlsx\n",
      "\n",
      "Selesai untuk file ini.\n"
     ]
    }
   ],
   "source": [
    "#KONFIG BERBEDA EPOCH 114 \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# ============ SEEDS ============\n",
    "def reset_seeds():\n",
    "    np.random.seed(42)\n",
    "    python_random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "reset_seeds()\n",
    "\n",
    "# ============ KONFIG TETAP (HASIL TERBAIK) ============\n",
    "FIXED_WINDOW_SIZE = 90\n",
    "FIXED_EPOCH = 114\n",
    "FIXED_BATCH_SIZE = 64\n",
    "VAL_RATIO = 0.1\n",
    "\n",
    "# ============ PATH FILE (GANTI PER WILAYAH) ============\n",
    "path_file_input = r\"E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Banyuwangi.xlsx\"\n",
    "output_root = r\"E:\\SKRIPSI 2025\\dataset\"\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "# ============ UTIL ============\n",
    "def create_sliding_window(dataset, window_size):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - window_size):\n",
    "        X.append(dataset[i:(i + window_size), 0])\n",
    "        Y.append(dataset[i + window_size, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def build_model_lstm(input_shape):\n",
    "    tf.random.set_seed(42)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.02))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(0.02))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# ============ LOAD DATA (SATU EXCEL) ============\n",
    "if not os.path.exists(path_file_input):\n",
    "    raise FileNotFoundError(f\"File tidak ditemukan: {path_file_input}\")\n",
    "\n",
    "df = pd.read_excel(path_file_input)\n",
    "if 'Harga (Rp)' not in df.columns:\n",
    "    raise KeyError(f\"Kolom 'Harga (Rp)' tidak ditemukan di file {path_file_input}\")\n",
    "\n",
    "raw_data = df['Harga (Rp)'].values.reshape(-1, 1)\n",
    "print(f\"✓ Data: {path_file_input}\")\n",
    "print(f\"✓ Jumlah baris asli (raw): {len(raw_data)}\")\n",
    "\n",
    "region_name = os.path.basename(path_file_input).replace(\"Data_Clean_\", \"\").replace(\".xlsx\", \"\")\n",
    "\n",
    "# ============ WINDOW DI SKALA ASLI ============\n",
    "X_full_raw, Y_full_raw = create_sliding_window(raw_data, FIXED_WINDOW_SIZE)\n",
    "print(f\"✓ Sampel window: {len(X_full_raw)} (window={FIXED_WINDOW_SIZE})\")\n",
    "train_size = int(len(X_full_raw) * 0.8)\n",
    "y_test_orig = Y_full_raw[train_size:]  # uji di skala asli\n",
    "\n",
    "# ============ SCALER FIT HANYA TRAIN (ANTI-LEAKAGE) ============\n",
    "raw_train_segment = raw_data[:train_size + FIXED_WINDOW_SIZE]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(raw_train_segment)\n",
    "scaled_data = scaler.transform(raw_data)\n",
    "print(\"✓ Data ternormalisasi (0-1).\")\n",
    "\n",
    "# ============ WINDOWING PADA DATA SCALED ============\n",
    "X_full_scaled, Y_full_scaled = create_sliding_window(scaled_data, FIXED_WINDOW_SIZE)\n",
    "X_full_scaled = X_full_scaled.reshape(X_full_scaled.shape[0], X_full_scaled.shape[1], 1)\n",
    "\n",
    "X_train_all, X_test = X_full_scaled[:train_size], X_full_scaled[train_size:]\n",
    "y_train_all = Y_full_scaled[:train_size]\n",
    "\n",
    "# Validasi tail dari TRAIN\n",
    "val_cut = int(len(X_train_all) * (1 - VAL_RATIO))\n",
    "X_train, X_val = X_train_all[:val_cut], X_train_all[val_cut:]\n",
    "y_train, y_val = y_train_all[:val_cut], y_train_all[val_cut:]\n",
    "\n",
    "print(f\"[Info] Total: {len(X_full_scaled)} | Train: {len(X_train_all)} | Val: {len(X_val)} | Test: {len(X_test)}\")\n",
    "\n",
    "# ============ TRAINING DENGAN KONFIG TETAP ============\n",
    "reset_seeds()\n",
    "model = build_model_lstm((X_train.shape[1], 1))\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=FIXED_EPOCH,\n",
    "    batch_size=FIXED_BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=0,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history.get('val_loss', None)\n",
    "last_loss = float(train_loss[-1])\n",
    "last_val_loss = float(val_loss[-1]) if val_loss is not None else None\n",
    "best_epoch = int(np.argmin(val_loss) + 1) if val_loss is not None else int(np.argmin(train_loss) + 1)\n",
    "best_val = float(np.min(val_loss)) if val_loss is not None else float(np.min(train_loss))\n",
    "\n",
    "print(f\"   -> Selesai epoch : {FIXED_EPOCH}\")\n",
    "print(f\"   -> Best epoch    : {best_epoch} (val_loss={best_val:.6f})\")\n",
    "print(f\"   -> Last loss     : {last_loss:.6f}\" + (f\" | Last val_loss : {last_val_loss:.6f}\" if last_val_loss is not None else \"\"))\n",
    "\n",
    "# ============ EVALUASI DI TEST (DENORMALIZED) ============\n",
    "predictions_scaled = model.predict(X_test, verbose=0)\n",
    "predictions_real = scaler.inverse_transform(predictions_scaled)\n",
    "mape = mean_absolute_percentage_error(y_test_orig.ravel(), predictions_real.ravel()) * 100\n",
    "print(f\"   -> MAPE          : {mape:.4f}%\")\n",
    "\n",
    "# ============ OUTPUT ============\n",
    "region_out_dir = os.path.join(output_root, f\"{region_name}_w{FIXED_WINDOW_SIZE}_e{FIXED_EPOCH}_b{FIXED_BATCH_SIZE}\")\n",
    "os.makedirs(region_out_dir, exist_ok=True)\n",
    "\n",
    "# Plot Actual vs Predicted\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(y_test_orig, label='Actual (Real Data)')\n",
    "plt.plot(predictions_real, label='Predicted (Denormalized)')\n",
    "plt.title(f'{region_name} | W{FIXED_WINDOW_SIZE} E{FIXED_EPOCH} B{FIXED_BATCH_SIZE}')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Harga')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plot_path = os.path.join(region_out_dir, f\"{region_name}_Plot.png\")\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"   ✓ Plot disimpan: {plot_path}\")\n",
    "\n",
    "# Excel per-baris\n",
    "y_test_safe = np.where(y_test_orig.flatten() == 0, np.finfo(float).eps, y_test_orig.flatten())\n",
    "err_pct = np.abs((y_test_orig.flatten() - predictions_real.flatten()) / y_test_safe) * 100\n",
    "out_df = pd.DataFrame({\n",
    "    'Actual (Real)': y_test_orig.flatten(),\n",
    "    'Predicted (Real)': predictions_real.flatten(),\n",
    "    'Selisih': (y_test_orig.flatten() - predictions_real.flatten()),\n",
    "    'Error (%)': err_pct\n",
    "})\n",
    "excel_path = os.path.join(region_out_dir, f\"{region_name}_Prediksi_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "out_df.to_excel(excel_path, index=False)\n",
    "print(f\"   ✓ Prediksi disimpan: {excel_path}\")\n",
    "\n",
    "# Ringkasan singkat\n",
    "summary = pd.DataFrame([{\n",
    "    'Region': region_name,\n",
    "    'Window Size': int(FIXED_WINDOW_SIZE),\n",
    "    'Epoch': int(FIXED_EPOCH),\n",
    "    'Batch Size': int(FIXED_BATCH_SIZE),\n",
    "    'Best Epoch (val)': int(best_epoch),\n",
    "    'Best Val Loss': float(best_val),\n",
    "    'Last Loss': float(last_loss),\n",
    "    'Last Val Loss': float(last_val_loss) if last_val_loss is not None else None,\n",
    "    'MAPE (%)': float(mape)\n",
    "}])\n",
    "summary_path = os.path.join(region_out_dir, f\"{region_name}_Summary_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "summary.to_excel(summary_path, index=False)\n",
    "print(f\"   ✓ Ringkasan disimpan: {summary_path}\")\n",
    "\n",
    "print(\"\\nSelesai untuk file ini.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee4664e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data: E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Banyuwangi.xlsx\n",
      "✓ Jumlah baris asli (raw): 1043\n",
      "✓ Sampel window: 953 (window=90)\n",
      "✓ Data ternormalisasi (0-1).\n",
      "[Info] Total: 953 | Train: 762 | Val: 77 | Test: 191\n",
      "   -> Selesai epoch : 114\n",
      "   -> Best epoch    : 113 (val_loss=0.000439)\n",
      "   -> Last loss     : 0.000828 | Last val_loss : 0.000490\n",
      "   -> MAPE          : 2.8423%\n",
      "   ✓ Plot disimpan: E:\\SKRIPSI 2025\\Banyuwangi_w90_e114_b64\\Banyuwangi_Plot.png\n",
      "   ✓ Prediksi disimpan: E:\\SKRIPSI 2025\\Banyuwangi_w90_e114_b64\\Banyuwangi_Prediksi_W90_E114_B64.xlsx\n",
      "   ✓ Ringkasan disimpan: E:\\SKRIPSI 2025\\Banyuwangi_w90_e114_b64\\Banyuwangi_Summary_W90_E114_B64.xlsx\n",
      "\n",
      "Selesai untuk file ini.\n"
     ]
    }
   ],
   "source": [
    "#KONFIG BERBEDA EPOCH 114 DDROPOUT 0.2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# ============ SEEDS ============\n",
    "def reset_seeds():\n",
    "    np.random.seed(42)\n",
    "    python_random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "reset_seeds()\n",
    "\n",
    "# ============ KONFIG TETAP (HASIL TERBAIK) ============\n",
    "FIXED_WINDOW_SIZE = 90\n",
    "FIXED_EPOCH = 114\n",
    "FIXED_BATCH_SIZE = 64\n",
    "VAL_RATIO = 0.1\n",
    "\n",
    "# ============ PATH FILE (GANTI PER WILAYAH) ============\n",
    "path_file_input = r\"E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Banyuwangi.xlsx\"\n",
    "output_root = r\"E:\\SKRIPSI 2025\"\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "# ============ UTIL ============\n",
    "def create_sliding_window(dataset, window_size):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - window_size):\n",
    "        X.append(dataset[i:(i + window_size), 0])\n",
    "        Y.append(dataset[i + window_size, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def build_model_lstm(input_shape):\n",
    "    tf.random.set_seed(42)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# ============ LOAD DATA (SATU EXCEL) ============\n",
    "if not os.path.exists(path_file_input):\n",
    "    raise FileNotFoundError(f\"File tidak ditemukan: {path_file_input}\")\n",
    "\n",
    "df = pd.read_excel(path_file_input)\n",
    "if 'Harga (Rp)' not in df.columns:\n",
    "    raise KeyError(f\"Kolom 'Harga (Rp)' tidak ditemukan di file {path_file_input}\")\n",
    "\n",
    "raw_data = df['Harga (Rp)'].values.reshape(-1, 1)\n",
    "print(f\"✓ Data: {path_file_input}\")\n",
    "print(f\"✓ Jumlah baris asli (raw): {len(raw_data)}\")\n",
    "\n",
    "region_name = os.path.basename(path_file_input).replace(\"Data_Clean_\", \"\").replace(\".xlsx\", \"\")\n",
    "\n",
    "# ============ WINDOW DI SKALA ASLI ============\n",
    "X_full_raw, Y_full_raw = create_sliding_window(raw_data, FIXED_WINDOW_SIZE)\n",
    "print(f\"✓ Sampel window: {len(X_full_raw)} (window={FIXED_WINDOW_SIZE})\")\n",
    "train_size = int(len(X_full_raw) * 0.8)\n",
    "y_test_orig = Y_full_raw[train_size:]  # uji di skala asli\n",
    "\n",
    "# ============ SCALER FIT HANYA TRAIN (ANTI-LEAKAGE) ============\n",
    "raw_train_segment = raw_data[:train_size + FIXED_WINDOW_SIZE]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(raw_train_segment)\n",
    "scaled_data = scaler.transform(raw_data)\n",
    "print(\"✓ Data ternormalisasi (0-1).\")\n",
    "\n",
    "# ============ WINDOWING PADA DATA SCALED ============\n",
    "X_full_scaled, Y_full_scaled = create_sliding_window(scaled_data, FIXED_WINDOW_SIZE)\n",
    "X_full_scaled = X_full_scaled.reshape(X_full_scaled.shape[0], X_full_scaled.shape[1], 1)\n",
    "\n",
    "X_train_all, X_test = X_full_scaled[:train_size], X_full_scaled[train_size:]\n",
    "y_train_all = Y_full_scaled[:train_size]\n",
    "\n",
    "# Validasi tail dari TRAIN\n",
    "val_cut = int(len(X_train_all) * (1 - VAL_RATIO))\n",
    "X_train, X_val = X_train_all[:val_cut], X_train_all[val_cut:]\n",
    "y_train, y_val = y_train_all[:val_cut], y_train_all[val_cut:]\n",
    "\n",
    "print(f\"[Info] Total: {len(X_full_scaled)} | Train: {len(X_train_all)} | Val: {len(X_val)} | Test: {len(X_test)}\")\n",
    "\n",
    "# ============ TRAINING DENGAN KONFIG TETAP ============\n",
    "reset_seeds()\n",
    "model = build_model_lstm((X_train.shape[1], 1))\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=FIXED_EPOCH,\n",
    "    batch_size=FIXED_BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=0,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history.get('val_loss', None)\n",
    "last_loss = float(train_loss[-1])\n",
    "last_val_loss = float(val_loss[-1]) if val_loss is not None else None\n",
    "best_epoch = int(np.argmin(val_loss) + 1) if val_loss is not None else int(np.argmin(train_loss) + 1)\n",
    "best_val = float(np.min(val_loss)) if val_loss is not None else float(np.min(train_loss))\n",
    "\n",
    "print(f\"   -> Selesai epoch : {FIXED_EPOCH}\")\n",
    "print(f\"   -> Best epoch    : {best_epoch} (val_loss={best_val:.6f})\")\n",
    "print(f\"   -> Last loss     : {last_loss:.6f}\" + (f\" | Last val_loss : {last_val_loss:.6f}\" if last_val_loss is not None else \"\"))\n",
    "\n",
    "# ============ EVALUASI DI TEST (DENORMALIZED) ============\n",
    "predictions_scaled = model.predict(X_test, verbose=0)\n",
    "predictions_real = scaler.inverse_transform(predictions_scaled)\n",
    "mape = mean_absolute_percentage_error(y_test_orig.ravel(), predictions_real.ravel()) * 100\n",
    "print(f\"   -> MAPE          : {mape:.4f}%\")\n",
    "\n",
    "# ============ OUTPUT ============\n",
    "region_out_dir = os.path.join(output_root, f\"{region_name}_w{FIXED_WINDOW_SIZE}_e{FIXED_EPOCH}_b{FIXED_BATCH_SIZE}\")\n",
    "os.makedirs(region_out_dir, exist_ok=True)\n",
    "\n",
    "# Plot Actual vs Predicted\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(y_test_orig, label='Actual (Real Data)')\n",
    "plt.plot(predictions_real, label='Predicted (Denormalized)')\n",
    "plt.title(f'{region_name} | W{FIXED_WINDOW_SIZE} E{FIXED_EPOCH} B{FIXED_BATCH_SIZE}')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Harga')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plot_path = os.path.join(region_out_dir, f\"{region_name}_Plot.png\")\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"   ✓ Plot disimpan: {plot_path}\")\n",
    "\n",
    "# Excel per-baris\n",
    "y_test_safe = np.where(y_test_orig.flatten() == 0, np.finfo(float).eps, y_test_orig.flatten())\n",
    "err_pct = np.abs((y_test_orig.flatten() - predictions_real.flatten()) / y_test_safe) * 100\n",
    "out_df = pd.DataFrame({\n",
    "    'Actual (Real)': y_test_orig.flatten(),\n",
    "    'Predicted (Real)': predictions_real.flatten(),\n",
    "    'Selisih': (y_test_orig.flatten() - predictions_real.flatten()),\n",
    "    'Error (%)': err_pct\n",
    "})\n",
    "excel_path = os.path.join(region_out_dir, f\"{region_name}_Prediksi_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "out_df.to_excel(excel_path, index=False)\n",
    "print(f\"   ✓ Prediksi disimpan: {excel_path}\")\n",
    "\n",
    "# Ringkasan singkat\n",
    "summary = pd.DataFrame([{\n",
    "    'Region': region_name,\n",
    "    'Window Size': int(FIXED_WINDOW_SIZE),\n",
    "    'Epoch': int(FIXED_EPOCH),\n",
    "    'Batch Size': int(FIXED_BATCH_SIZE),\n",
    "    'Best Epoch (val)': int(best_epoch),\n",
    "    'Best Val Loss': float(best_val),\n",
    "    'Last Loss': float(last_loss),\n",
    "    'Last Val Loss': float(last_val_loss) if last_val_loss is not None else None,\n",
    "    'MAPE (%)': float(mape)\n",
    "}])\n",
    "summary_path = os.path.join(region_out_dir, f\"{region_name}_Summary_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "summary.to_excel(summary_path, index=False)\n",
    "print(f\"   ✓ Ringkasan disimpan: {summary_path}\")\n",
    "\n",
    "print(\"\\nSelesai untuk file ini.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd25fa29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data: E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Banyuwangi.xlsx\n",
      "✓ Jumlah baris asli (raw): 1043\n",
      "✓ Sampel window: 1036 (window=7)\n",
      "✓ Data ternormalisasi (0-1).\n",
      "[Info] Total: 1036 | Train: 828 | Val: 83 | Test: 208\n",
      "   -> Selesai epoch : 114\n",
      "   -> Best epoch    : 114 (val_loss=0.000274)\n",
      "   -> Last loss     : 0.000716 | Last val_loss : 0.000274\n",
      "   -> MAPE          : 2.6209%\n",
      "   ✓ Plot disimpan: E:\\SKRIPSI 2025\\Banyuwangi_w7_e114_b64\\Banyuwangi_Plot.png\n",
      "   ✓ Prediksi disimpan: E:\\SKRIPSI 2025\\Banyuwangi_w7_e114_b64\\Banyuwangi_Prediksi_W7_E114_B64.xlsx\n",
      "   ✓ Ringkasan disimpan: E:\\SKRIPSI 2025\\Banyuwangi_w7_e114_b64\\Banyuwangi_Summary_W7_E114_B64.xlsx\n",
      "\n",
      "Selesai untuk file ini.\n"
     ]
    }
   ],
   "source": [
    "#KONFIG BERBEDA EPOCH 114 DDROPOUT 0.02 WINDOWSIZE 7\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# ============ SEEDS ============\n",
    "def reset_seeds():\n",
    "    np.random.seed(42)\n",
    "    python_random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "reset_seeds()\n",
    "\n",
    "# ============ KONFIG TETAP (HASIL TERBAIK) ============\n",
    "FIXED_WINDOW_SIZE = 7\n",
    "FIXED_EPOCH = 114\n",
    "FIXED_BATCH_SIZE = 64\n",
    "VAL_RATIO = 0.1\n",
    "\n",
    "# ============ PATH FILE (GANTI PER WILAYAH) ============\n",
    "path_file_input = r\"E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Banyuwangi.xlsx\"\n",
    "output_root = r\"E:\\SKRIPSI 2025\"\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "# ============ UTIL ============\n",
    "def create_sliding_window(dataset, window_size):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - window_size):\n",
    "        X.append(dataset[i:(i + window_size), 0])\n",
    "        Y.append(dataset[i + window_size, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def build_model_lstm(input_shape):\n",
    "    tf.random.set_seed(42)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# ============ LOAD DATA (SATU EXCEL) ============\n",
    "if not os.path.exists(path_file_input):\n",
    "    raise FileNotFoundError(f\"File tidak ditemukan: {path_file_input}\")\n",
    "\n",
    "df = pd.read_excel(path_file_input)\n",
    "if 'Harga (Rp)' not in df.columns:\n",
    "    raise KeyError(f\"Kolom 'Harga (Rp)' tidak ditemukan di file {path_file_input}\")\n",
    "\n",
    "raw_data = df['Harga (Rp)'].values.reshape(-1, 1)\n",
    "print(f\"✓ Data: {path_file_input}\")\n",
    "print(f\"✓ Jumlah baris asli (raw): {len(raw_data)}\")\n",
    "\n",
    "region_name = os.path.basename(path_file_input).replace(\"Data_Clean_\", \"\").replace(\".xlsx\", \"\")\n",
    "\n",
    "# ============ WINDOW DI SKALA ASLI ============\n",
    "X_full_raw, Y_full_raw = create_sliding_window(raw_data, FIXED_WINDOW_SIZE)\n",
    "print(f\"✓ Sampel window: {len(X_full_raw)} (window={FIXED_WINDOW_SIZE})\")\n",
    "train_size = int(len(X_full_raw) * 0.8)\n",
    "y_test_orig = Y_full_raw[train_size:]  # uji di skala asli\n",
    "\n",
    "# ============ SCALER FIT HANYA TRAIN (ANTI-LEAKAGE) ============\n",
    "raw_train_segment = raw_data[:train_size + FIXED_WINDOW_SIZE]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(raw_train_segment)\n",
    "scaled_data = scaler.transform(raw_data)\n",
    "print(\"✓ Data ternormalisasi (0-1).\")\n",
    "\n",
    "# ============ WINDOWING PADA DATA SCALED ============\n",
    "X_full_scaled, Y_full_scaled = create_sliding_window(scaled_data, FIXED_WINDOW_SIZE)\n",
    "X_full_scaled = X_full_scaled.reshape(X_full_scaled.shape[0], X_full_scaled.shape[1], 1)\n",
    "\n",
    "X_train_all, X_test = X_full_scaled[:train_size], X_full_scaled[train_size:]\n",
    "y_train_all = Y_full_scaled[:train_size]\n",
    "\n",
    "# Validasi tail dari TRAIN\n",
    "val_cut = int(len(X_train_all) * (1 - VAL_RATIO))\n",
    "X_train, X_val = X_train_all[:val_cut], X_train_all[val_cut:]\n",
    "y_train, y_val = y_train_all[:val_cut], y_train_all[val_cut:]\n",
    "\n",
    "print(f\"[Info] Total: {len(X_full_scaled)} | Train: {len(X_train_all)} | Val: {len(X_val)} | Test: {len(X_test)}\")\n",
    "\n",
    "# ============ TRAINING DENGAN KONFIG TETAP ============\n",
    "reset_seeds()\n",
    "model = build_model_lstm((X_train.shape[1], 1))\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=FIXED_EPOCH,\n",
    "    batch_size=FIXED_BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=0,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history.get('val_loss', None)\n",
    "last_loss = float(train_loss[-1])\n",
    "last_val_loss = float(val_loss[-1]) if val_loss is not None else None\n",
    "best_epoch = int(np.argmin(val_loss) + 1) if val_loss is not None else int(np.argmin(train_loss) + 1)\n",
    "best_val = float(np.min(val_loss)) if val_loss is not None else float(np.min(train_loss))\n",
    "\n",
    "print(f\"   -> Selesai epoch : {FIXED_EPOCH}\")\n",
    "print(f\"   -> Best epoch    : {best_epoch} (val_loss={best_val:.6f})\")\n",
    "print(f\"   -> Last loss     : {last_loss:.6f}\" + (f\" | Last val_loss : {last_val_loss:.6f}\" if last_val_loss is not None else \"\"))\n",
    "\n",
    "# ============ EVALUASI DI TEST (DENORMALIZED) ============\n",
    "predictions_scaled = model.predict(X_test, verbose=0)\n",
    "predictions_real = scaler.inverse_transform(predictions_scaled)\n",
    "mape = mean_absolute_percentage_error(y_test_orig.ravel(), predictions_real.ravel()) * 100\n",
    "print(f\"   -> MAPE          : {mape:.4f}%\")\n",
    "\n",
    "# ============ OUTPUT ============\n",
    "region_out_dir = os.path.join(output_root, f\"{region_name}_w{FIXED_WINDOW_SIZE}_e{FIXED_EPOCH}_b{FIXED_BATCH_SIZE}\")\n",
    "os.makedirs(region_out_dir, exist_ok=True)\n",
    "\n",
    "# Plot Actual vs Predicted\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(y_test_orig, label='Actual (Real Data)')\n",
    "plt.plot(predictions_real, label='Predicted (Denormalized)')\n",
    "plt.title(f'{region_name} | W{FIXED_WINDOW_SIZE} E{FIXED_EPOCH} B{FIXED_BATCH_SIZE}')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Harga')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plot_path = os.path.join(region_out_dir, f\"{region_name}_Plot.png\")\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"   ✓ Plot disimpan: {plot_path}\")\n",
    "\n",
    "# Excel per-baris\n",
    "y_test_safe = np.where(y_test_orig.flatten() == 0, np.finfo(float).eps, y_test_orig.flatten())\n",
    "err_pct = np.abs((y_test_orig.flatten() - predictions_real.flatten()) / y_test_safe) * 100\n",
    "out_df = pd.DataFrame({\n",
    "    'Actual (Real)': y_test_orig.flatten(),\n",
    "    'Predicted (Real)': predictions_real.flatten(),\n",
    "    'Selisih': (y_test_orig.flatten() - predictions_real.flatten()),\n",
    "    'Error (%)': err_pct\n",
    "})\n",
    "excel_path = os.path.join(region_out_dir, f\"{region_name}_Prediksi_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "out_df.to_excel(excel_path, index=False)\n",
    "print(f\"   ✓ Prediksi disimpan: {excel_path}\")\n",
    "\n",
    "# Ringkasan singkat\n",
    "summary = pd.DataFrame([{\n",
    "    'Region': region_name,\n",
    "    'Window Size': int(FIXED_WINDOW_SIZE),\n",
    "    'Epoch': int(FIXED_EPOCH),\n",
    "    'Batch Size': int(FIXED_BATCH_SIZE),\n",
    "    'Best Epoch (val)': int(best_epoch),\n",
    "    'Best Val Loss': float(best_val),\n",
    "    'Last Loss': float(last_loss),\n",
    "    'Last Val Loss': float(last_val_loss) if last_val_loss is not None else None,\n",
    "    'MAPE (%)': float(mape)\n",
    "}])\n",
    "summary_path = os.path.join(region_out_dir, f\"{region_name}_Summary_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "summary.to_excel(summary_path, index=False)\n",
    "print(f\"   ✓ Ringkasan disimpan: {summary_path}\")\n",
    "\n",
    "print(\"\\nSelesai untuk file ini.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2a09df",
   "metadata": {},
   "source": [
    "UJI COBA FINAL CODE MEMBUAT MODEL .H5\n",
    "DENGAN KONFIG WINDOWSIZE 7 EPOCH 114 DROPOUT 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f55e669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data: E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Banyuwangi.xlsx\n",
      "✓ Jumlah baris asli (raw): 1043\n",
      "✓ Sampel window: 1036 (window=7)\n",
      "✓ Data ternormalisasi (0-1).\n",
      "[Info] Total: 1036 | Train: 828 | Val: 83 | Test: 208\n",
      "   -> Selesai epoch : 114\n",
      "   -> Best epoch    : 114 (val_loss=0.000274)\n",
      "   -> Last loss     : 0.000716 | Last val_loss : 0.000274\n",
      "   -> MAPE          : 2.6209%\n",
      "   ✓ Model disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Banyuwangi_w7_e114_b64\\Banyuwangi_model_W7_E114_B64_DO0.2.h5\n",
      "   ✓ Scaler disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Banyuwangi_w7_e114_b64\\Banyuwangi_scaler_W7_E114_B64_DO0.2.pkl\n",
      "   ✓ Metadata disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Banyuwangi_w7_e114_b64\\Banyuwangi_metadata.json\n",
      "   ✓ Plot disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Banyuwangi_w7_e114_b64\\Banyuwangi_Plot.png\n",
      "   ✓ Prediksi disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Banyuwangi_w7_e114_b64\\Banyuwangi_Prediksi_W7_E114_B64.xlsx\n",
      "   ✓ Ringkasan disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Banyuwangi_w7_e114_b64\\Banyuwangi_Summary_W7_E114_B64.xlsx\n",
      "\n",
      "Selesai untuk file ini.\n"
     ]
    }
   ],
   "source": [
    "#BANYUWANGI\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# ============ SEEDS ============\n",
    "def reset_seeds():\n",
    "    np.random.seed(42)\n",
    "    python_random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "reset_seeds()\n",
    "\n",
    "# ============ KONFIG TETAP (HASIL TERBAIK) ============\n",
    "FIXED_WINDOW_SIZE = 7\n",
    "FIXED_EPOCH = 114\n",
    "FIXED_BATCH_SIZE = 64\n",
    "VAL_RATIO = 0.1\n",
    "DROPOUT_RATE = 0.2\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# ============ PATH FILE (GANTI PER WILAYAH) ============\n",
    "path_file_input = r\"E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Banyuwangi.xlsx\"\n",
    "output_root = r\"E:\\SKRIPSI 2025\\dataset\\FINAL\"\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "# ============ UTIL ============\n",
    "def create_sliding_window(dataset, window_size):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - window_size):\n",
    "        X.append(dataset[i:(i + window_size), 0])\n",
    "        Y.append(dataset[i + window_size, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def build_model_lstm(input_shape):\n",
    "    tf.random.set_seed(42)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                  loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# ============ LOAD DATA (SATU EXCEL) ============\n",
    "if not os.path.exists(path_file_input):\n",
    "    raise FileNotFoundError(f\"File tidak ditemukan: {path_file_input}\")\n",
    "\n",
    "df = pd.read_excel(path_file_input)\n",
    "if 'Harga (Rp)' not in df.columns:\n",
    "    raise KeyError(f\"Kolom 'Harga (Rp)' tidak ditemukan di file {path_file_input}\")\n",
    "\n",
    "raw_data = df['Harga (Rp)'].values.reshape(-1, 1)\n",
    "print(f\"✓ Data: {path_file_input}\")\n",
    "print(f\"✓ Jumlah baris asli (raw): {len(raw_data)}\")\n",
    "\n",
    "region_name = os.path.basename(path_file_input).replace(\"Data_Clean_\", \"\").replace(\".xlsx\", \"\")\n",
    "\n",
    "# ============ WINDOW DI SKALA ASLI ============\n",
    "X_full_raw, Y_full_raw = create_sliding_window(raw_data, FIXED_WINDOW_SIZE)\n",
    "print(f\"✓ Sampel window: {len(X_full_raw)} (window={FIXED_WINDOW_SIZE})\")\n",
    "train_size = int(len(X_full_raw) * 0.8)\n",
    "y_test_orig = Y_full_raw[train_size:]  # uji di skala asli\n",
    "\n",
    "# ============ SCALER FIT HANYA TRAIN (ANTI-LEAKAGE) ============\n",
    "raw_train_segment = raw_data[:train_size + FIXED_WINDOW_SIZE]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(raw_train_segment)\n",
    "scaled_data = scaler.transform(raw_data)\n",
    "print(\"✓ Data ternormalisasi (0-1).\")\n",
    "\n",
    "# ============ WINDOWING PADA DATA SCALED ============\n",
    "X_full_scaled, Y_full_scaled = create_sliding_window(scaled_data, FIXED_WINDOW_SIZE)\n",
    "X_full_scaled = X_full_scaled.reshape(X_full_scaled.shape[0], X_full_scaled.shape[1], 1)\n",
    "\n",
    "X_train_all, X_test = X_full_scaled[:train_size], X_full_scaled[train_size:]\n",
    "y_train_all = Y_full_scaled[:train_size]\n",
    "\n",
    "# Validasi tail dari TRAIN\n",
    "val_cut = int(len(X_train_all) * (1 - VAL_RATIO))\n",
    "X_train, X_val = X_train_all[:val_cut], X_train_all[val_cut:]\n",
    "y_train, y_val = y_train_all[:val_cut], y_train_all[val_cut:]\n",
    "\n",
    "print(f\"[Info] Total: {len(X_full_scaled)} | Train: {len(X_train_all)} | Val: {len(X_val)} | Test: {len(X_test)}\")\n",
    "\n",
    "# ============ TRAINING DENGAN KONFIG TETAP ============\n",
    "reset_seeds()\n",
    "model = build_model_lstm((X_train.shape[1], 1))\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=FIXED_EPOCH,\n",
    "    batch_size=FIXED_BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=0,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history.get('val_loss', None)\n",
    "last_loss = float(train_loss[-1])\n",
    "last_val_loss = float(val_loss[-1]) if val_loss is not None else None\n",
    "best_epoch = int(np.argmin(val_loss) + 1) if val_loss is not None else int(np.argmin(train_loss) + 1)\n",
    "best_val = float(np.min(val_loss)) if val_loss is not None else float(np.min(train_loss))\n",
    "\n",
    "print(f\"   -> Selesai epoch : {FIXED_EPOCH}\")\n",
    "print(f\"   -> Best epoch    : {best_epoch} (val_loss={best_val:.6f})\")\n",
    "print(f\"   -> Last loss     : {last_loss:.6f}\" + (f\" | Last val_loss : {last_val_loss:.6f}\" if last_val_loss is not None else \"\"))\n",
    "\n",
    "# ============ EVALUASI DI TEST (DENORMALIZED) ============\n",
    "predictions_scaled = model.predict(X_test, verbose=0)\n",
    "predictions_real = scaler.inverse_transform(predictions_scaled)\n",
    "mape = mean_absolute_percentage_error(y_test_orig.ravel(), predictions_real.ravel()) * 100\n",
    "print(f\"   -> MAPE          : {mape:.4f}%\")\n",
    "\n",
    "# ============ OUTPUT ============\n",
    "region_out_dir = os.path.join(output_root, f\"{region_name}_w{FIXED_WINDOW_SIZE}_e{FIXED_EPOCH}_b{FIXED_BATCH_SIZE}\")\n",
    "os.makedirs(region_out_dir, exist_ok=True)\n",
    "\n",
    "# Simpan MODEL (.h5) dan SCALER (.pkl) + metadata\n",
    "model_path = os.path.join(region_out_dir, f\"{region_name}_model_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}_DO{DROPOUT_RATE}.h5\")\n",
    "scaler_path = os.path.join(region_out_dir, f\"{region_name}_scaler_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}_DO{DROPOUT_RATE}.pkl\")\n",
    "meta_path = os.path.join(region_out_dir, f\"{region_name}_metadata.json\")\n",
    "\n",
    "# Simpan model\n",
    "model.save(model_path)\n",
    "print(f\"   ✓ Model disimpan: {model_path}\")\n",
    "\n",
    "# Simpan scaler\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f\"   ✓ Scaler disimpan: {scaler_path}\")\n",
    "\n",
    "# Simpan metadata konfigurasi dan metrik\n",
    "metadata = {\n",
    "    \"region\": region_name,\n",
    "    \"window_size\": int(FIXED_WINDOW_SIZE),\n",
    "    \"epoch\": int(FIXED_EPOCH),\n",
    "    \"batch_size\": int(FIXED_BATCH_SIZE),\n",
    "    \"dropout_rate\": float(DROPOUT_RATE),\n",
    "    \"learning_rate\": float(LEARNING_RATE),\n",
    "    \"val_ratio\": float(VAL_RATIO),\n",
    "    \"train_samples\": int(len(X_train_all)),\n",
    "    \"val_samples\": int(len(X_val)),\n",
    "    \"test_samples\": int(len(X_test)),\n",
    "    \"best_epoch_val\": int(best_epoch),\n",
    "    \"best_val_loss\": float(best_val),\n",
    "    \"last_loss\": float(last_loss),\n",
    "    \"last_val_loss\": float(last_val_loss) if last_val_loss is not None else None,\n",
    "    \"mape_test_percent\": float(mape)\n",
    "}\n",
    "with open(meta_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "print(f\"   ✓ Metadata disimpan: {meta_path}\")\n",
    "\n",
    "# Plot Actual vs Predicted\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(y_test_orig, label='Actual (Real Data)')\n",
    "plt.plot(predictions_real, label='Predicted (Denormalized)')\n",
    "plt.title(f'{region_name} | W{FIXED_WINDOW_SIZE} E{FIXED_EPOCH} B{FIXED_BATCH_SIZE} DO{DROPOUT_RATE}')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Harga')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plot_path = os.path.join(region_out_dir, f\"{region_name}_Plot.png\")\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"   ✓ Plot disimpan: {plot_path}\")\n",
    "\n",
    "# Excel per-baris\n",
    "y_test_safe = np.where(y_test_orig.flatten() == 0, np.finfo(float).eps, y_test_orig.flatten())\n",
    "err_pct = np.abs((y_test_orig.flatten() - predictions_real.flatten()) / y_test_safe) * 100\n",
    "out_df = pd.DataFrame({\n",
    "    'Actual (Real)': y_test_orig.flatten(),\n",
    "    'Predicted (Real)': predictions_real.flatten(),\n",
    "    'Selisih': (y_test_orig.flatten() - predictions_real.flatten()),\n",
    "    'Error (%)': err_pct\n",
    "})\n",
    "excel_path = os.path.join(region_out_dir, f\"{region_name}_Prediksi_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "out_df.to_excel(excel_path, index=False)\n",
    "print(f\"   ✓ Prediksi disimpan: {excel_path}\")\n",
    "\n",
    "# Ringkasan singkat\n",
    "summary = pd.DataFrame([{\n",
    "    'Region': region_name,\n",
    "    'Window Size': int(FIXED_WINDOW_SIZE),\n",
    "    'Epoch': int(FIXED_EPOCH),\n",
    "    'Batch Size': int(FIXED_BATCH_SIZE),\n",
    "    'Dropout': float(DROPOUT_RATE),\n",
    "    'Best Epoch (val)': int(best_epoch),\n",
    "    'Best Val Loss': float(best_val),\n",
    "    'Last Loss': float(last_loss),\n",
    "    'Last Val Loss': float(last_val_loss) if last_val_loss is not None else None,\n",
    "    'MAPE (%)': float(mape)\n",
    "}])\n",
    "summary_path = os.path.join(region_out_dir, f\"{region_name}_Summary_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "summary.to_excel(summary_path, index=False)\n",
    "print(f\"   ✓ Ringkasan disimpan: {summary_path}\")\n",
    "\n",
    "print(\"\\nSelesai untuk file ini.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e48a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data: E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Surabaya.xlsx\n",
      "✓ Jumlah baris asli (raw): 1043\n",
      "✓ Sampel window: 1036 (window=7)\n",
      "✓ Data ternormalisasi (0-1).\n",
      "[Info] Total: 1036 | Train: 828 | Val: 83 | Test: 208\n",
      "   -> Selesai epoch : 114\n",
      "   -> Best epoch    : 111 (val_loss=0.000227)\n",
      "   -> Last loss     : 0.000980 | Last val_loss : 0.000441\n",
      "   -> MAPE          : 3.7366%\n",
      "   ✓ Model disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Surabaya_w7_e114_b64\\Surabaya_model_W7_E114_B64_DO0.2.h5\n",
      "   ✓ Scaler disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Surabaya_w7_e114_b64\\Surabaya_scaler_W7_E114_B64_DO0.2.pkl\n",
      "   ✓ Metadata disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Surabaya_w7_e114_b64\\Surabaya_metadata.json\n",
      "   ✓ Plot disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Surabaya_w7_e114_b64\\Surabaya_Plot.png\n",
      "   ✓ Prediksi disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Surabaya_w7_e114_b64\\Surabaya_Prediksi_W7_E114_B64.xlsx\n",
      "   ✓ Ringkasan disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Surabaya_w7_e114_b64\\Surabaya_Summary_W7_E114_B64.xlsx\n",
      "\n",
      "Selesai untuk file ini.\n"
     ]
    }
   ],
   "source": [
    "#SURABAYA\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# ============ SEEDS ============\n",
    "def reset_seeds():\n",
    "    np.random.seed(42)\n",
    "    python_random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "reset_seeds()\n",
    "\n",
    "# ============ KONFIG TETAP (HASIL TERBAIK) ============\n",
    "FIXED_WINDOW_SIZE = 7\n",
    "FIXED_EPOCH = 114\n",
    "FIXED_BATCH_SIZE = 64\n",
    "VAL_RATIO = 0.1\n",
    "DROPOUT_RATE = 0.2\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# ============ PATH FILE (GANTI PER WILAYAH) ============\n",
    "path_file_input = r\"E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Surabaya.xlsx\"\n",
    "output_root = r\"E:\\SKRIPSI 2025\\dataset\\FINAL\"\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "# ============ UTIL ============\n",
    "def create_sliding_window(dataset, window_size):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - window_size):\n",
    "        X.append(dataset[i:(i + window_size), 0])\n",
    "        Y.append(dataset[i + window_size, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def build_model_lstm(input_shape):\n",
    "    tf.random.set_seed(42)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                  loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# ============ LOAD DATA (SATU EXCEL) ============\n",
    "if not os.path.exists(path_file_input):\n",
    "    raise FileNotFoundError(f\"File tidak ditemukan: {path_file_input}\")\n",
    "\n",
    "df = pd.read_excel(path_file_input)\n",
    "if 'Harga (Rp)' not in df.columns:\n",
    "    raise KeyError(f\"Kolom 'Harga (Rp)' tidak ditemukan di file {path_file_input}\")\n",
    "\n",
    "raw_data = df['Harga (Rp)'].values.reshape(-1, 1)\n",
    "print(f\"✓ Data: {path_file_input}\")\n",
    "print(f\"✓ Jumlah baris asli (raw): {len(raw_data)}\")\n",
    "\n",
    "region_name = os.path.basename(path_file_input).replace(\"Data_Clean_\", \"\").replace(\".xlsx\", \"\")\n",
    "\n",
    "# ============ WINDOW DI SKALA ASLI ============\n",
    "X_full_raw, Y_full_raw = create_sliding_window(raw_data, FIXED_WINDOW_SIZE)\n",
    "print(f\"✓ Sampel window: {len(X_full_raw)} (window={FIXED_WINDOW_SIZE})\")\n",
    "train_size = int(len(X_full_raw) * 0.8)\n",
    "y_test_orig = Y_full_raw[train_size:]  # uji di skala asli\n",
    "\n",
    "# ============ SCALER FIT HANYA TRAIN (ANTI-LEAKAGE) ============\n",
    "raw_train_segment = raw_data[:train_size + FIXED_WINDOW_SIZE]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(raw_train_segment)\n",
    "scaled_data = scaler.transform(raw_data)\n",
    "print(\"✓ Data ternormalisasi (0-1).\")\n",
    "\n",
    "# ============ WINDOWING PADA DATA SCALED ============\n",
    "X_full_scaled, Y_full_scaled = create_sliding_window(scaled_data, FIXED_WINDOW_SIZE)\n",
    "X_full_scaled = X_full_scaled.reshape(X_full_scaled.shape[0], X_full_scaled.shape[1], 1)\n",
    "\n",
    "X_train_all, X_test = X_full_scaled[:train_size], X_full_scaled[train_size:]\n",
    "y_train_all = Y_full_scaled[:train_size]\n",
    "\n",
    "# Validasi tail dari TRAIN\n",
    "val_cut = int(len(X_train_all) * (1 - VAL_RATIO))\n",
    "X_train, X_val = X_train_all[:val_cut], X_train_all[val_cut:]\n",
    "y_train, y_val = y_train_all[:val_cut], y_train_all[val_cut:]\n",
    "\n",
    "print(f\"[Info] Total: {len(X_full_scaled)} | Train: {len(X_train_all)} | Val: {len(X_val)} | Test: {len(X_test)}\")\n",
    "\n",
    "# ============ TRAINING DENGAN KONFIG TETAP ============\n",
    "reset_seeds()\n",
    "model = build_model_lstm((X_train.shape[1], 1))\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=FIXED_EPOCH,\n",
    "    batch_size=FIXED_BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=0,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history.get('val_loss', None)\n",
    "last_loss = float(train_loss[-1])\n",
    "last_val_loss = float(val_loss[-1]) if val_loss is not None else None\n",
    "best_epoch = int(np.argmin(val_loss) + 1) if val_loss is not None else int(np.argmin(train_loss) + 1)\n",
    "best_val = float(np.min(val_loss)) if val_loss is not None else float(np.min(train_loss))\n",
    "\n",
    "print(f\"   -> Selesai epoch : {FIXED_EPOCH}\")\n",
    "print(f\"   -> Best epoch    : {best_epoch} (val_loss={best_val:.6f})\")\n",
    "print(f\"   -> Last loss     : {last_loss:.6f}\" + (f\" | Last val_loss : {last_val_loss:.6f}\" if last_val_loss is not None else \"\"))\n",
    "\n",
    "# ============ EVALUASI DI TEST (DENORMALIZED) ============\n",
    "predictions_scaled = model.predict(X_test, verbose=0)\n",
    "predictions_real = scaler.inverse_transform(predictions_scaled)\n",
    "mape = mean_absolute_percentage_error(y_test_orig.ravel(), predictions_real.ravel()) * 100\n",
    "print(f\"   -> MAPE          : {mape:.4f}%\")\n",
    "\n",
    "# ============ OUTPUT ============\n",
    "region_out_dir = os.path.join(output_root, f\"{region_name}_w{FIXED_WINDOW_SIZE}_e{FIXED_EPOCH}_b{FIXED_BATCH_SIZE}\")\n",
    "os.makedirs(region_out_dir, exist_ok=True)\n",
    "\n",
    "# Simpan MODEL (.h5) dan SCALER (.pkl) + metadata\n",
    "model_path = os.path.join(region_out_dir, f\"{region_name}_model_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}_DO{DROPOUT_RATE}.h5\")\n",
    "scaler_path = os.path.join(region_out_dir, f\"{region_name}_scaler_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}_DO{DROPOUT_RATE}.pkl\")\n",
    "meta_path = os.path.join(region_out_dir, f\"{region_name}_metadata.json\")\n",
    "\n",
    "# Simpan model\n",
    "model.save(model_path)\n",
    "print(f\"   ✓ Model disimpan: {model_path}\")\n",
    "\n",
    "# Simpan scaler\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f\"   ✓ Scaler disimpan: {scaler_path}\")\n",
    "\n",
    "# Simpan metadata konfigurasi dan metrik\n",
    "metadata = {\n",
    "    \"region\": region_name,\n",
    "    \"window_size\": int(FIXED_WINDOW_SIZE),\n",
    "    \"epoch\": int(FIXED_EPOCH),\n",
    "    \"batch_size\": int(FIXED_BATCH_SIZE),\n",
    "    \"dropout_rate\": float(DROPOUT_RATE),\n",
    "    \"learning_rate\": float(LEARNING_RATE),\n",
    "    \"val_ratio\": float(VAL_RATIO),\n",
    "    \"train_samples\": int(len(X_train_all)),\n",
    "    \"val_samples\": int(len(X_val)),\n",
    "    \"test_samples\": int(len(X_test)),\n",
    "    \"best_epoch_val\": int(best_epoch),\n",
    "    \"best_val_loss\": float(best_val),\n",
    "    \"last_loss\": float(last_loss),\n",
    "    \"last_val_loss\": float(last_val_loss) if last_val_loss is not None else None,\n",
    "    \"mape_test_percent\": float(mape)\n",
    "}\n",
    "with open(meta_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "print(f\"   ✓ Metadata disimpan: {meta_path}\")\n",
    "\n",
    "# Plot Actual vs Predicted\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(y_test_orig, label='Actual (Real Data)')\n",
    "plt.plot(predictions_real, label='Predicted (Denormalized)')\n",
    "plt.title(f'{region_name} | W{FIXED_WINDOW_SIZE} E{FIXED_EPOCH} B{FIXED_BATCH_SIZE} DO{DROPOUT_RATE}')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Harga')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plot_path = os.path.join(region_out_dir, f\"{region_name}_Plot.png\")\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"   ✓ Plot disimpan: {plot_path}\")\n",
    "\n",
    "# Excel per-baris\n",
    "y_test_safe = np.where(y_test_orig.flatten() == 0, np.finfo(float).eps, y_test_orig.flatten())\n",
    "err_pct = np.abs((y_test_orig.flatten() - predictions_real.flatten()) / y_test_safe) * 100\n",
    "out_df = pd.DataFrame({\n",
    "    'Actual (Real)': y_test_orig.flatten(),\n",
    "    'Predicted (Real)': predictions_real.flatten(),\n",
    "    'Selisih': (y_test_orig.flatten() - predictions_real.flatten()),\n",
    "    'Error (%)': err_pct\n",
    "})\n",
    "excel_path = os.path.join(region_out_dir, f\"{region_name}_Prediksi_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "out_df.to_excel(excel_path, index=False)\n",
    "print(f\"   ✓ Prediksi disimpan: {excel_path}\")\n",
    "\n",
    "# Ringkasan singkat\n",
    "summary = pd.DataFrame([{\n",
    "    'Region': region_name,\n",
    "    'Window Size': int(FIXED_WINDOW_SIZE),\n",
    "    'Epoch': int(FIXED_EPOCH),\n",
    "    'Batch Size': int(FIXED_BATCH_SIZE),\n",
    "    'Dropout': float(DROPOUT_RATE),\n",
    "    'Best Epoch (val)': int(best_epoch),\n",
    "    'Best Val Loss': float(best_val),\n",
    "    'Last Loss': float(last_loss),\n",
    "    'Last Val Loss': float(last_val_loss) if last_val_loss is not None else None,\n",
    "    'MAPE (%)': float(mape)\n",
    "}])\n",
    "summary_path = os.path.join(region_out_dir, f\"{region_name}_Summary_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "summary.to_excel(summary_path, index=False)\n",
    "print(f\"   ✓ Ringkasan disimpan: {summary_path}\")\n",
    "\n",
    "print(\"\\nSelesai untuk file ini.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d41a402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data: E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Blitar.xlsx\n",
      "✓ Jumlah baris asli (raw): 1043\n",
      "✓ Sampel window: 1036 (window=7)\n",
      "✓ Data ternormalisasi (0-1).\n",
      "[Info] Total: 1036 | Train: 828 | Val: 83 | Test: 208\n",
      "   -> Selesai epoch : 114\n",
      "   -> Best epoch    : 107 (val_loss=0.000592)\n",
      "   -> Last loss     : 0.001126 | Last val_loss : 0.000662\n",
      "   -> MAPE          : 3.3419%\n",
      "   ✓ Model disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Blitar_w7_e114_b64\\Blitar_model_W7_E114_B64_DO0.2.h5\n",
      "   ✓ Scaler disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Blitar_w7_e114_b64\\Blitar_scaler_W7_E114_B64_DO0.2.pkl\n",
      "   ✓ Metadata disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Blitar_w7_e114_b64\\Blitar_metadata.json\n",
      "   ✓ Plot disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Blitar_w7_e114_b64\\Blitar_Plot.png\n",
      "   ✓ Prediksi disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Blitar_w7_e114_b64\\Blitar_Prediksi_W7_E114_B64.xlsx\n",
      "   ✓ Ringkasan disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Blitar_w7_e114_b64\\Blitar_Summary_W7_E114_B64.xlsx\n",
      "\n",
      "Selesai untuk file ini.\n"
     ]
    }
   ],
   "source": [
    "#BLITAR\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# ============ SEEDS ============\n",
    "def reset_seeds():\n",
    "    np.random.seed(42)\n",
    "    python_random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "reset_seeds()\n",
    "\n",
    "# ============ KONFIG TETAP (HASIL TERBAIK) ============\n",
    "FIXED_WINDOW_SIZE = 7\n",
    "FIXED_EPOCH = 114\n",
    "FIXED_BATCH_SIZE = 64\n",
    "VAL_RATIO = 0.1\n",
    "DROPOUT_RATE = 0.2\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# ============ PATH FILE (GANTI PER WILAYAH) ============\n",
    "path_file_input = r\"E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Blitar.xlsx\"\n",
    "output_root = r\"E:\\SKRIPSI 2025\\dataset\\FINAL\"\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "# ============ UTIL ============\n",
    "def create_sliding_window(dataset, window_size):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - window_size):\n",
    "        X.append(dataset[i:(i + window_size), 0])\n",
    "        Y.append(dataset[i + window_size, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def build_model_lstm(input_shape):\n",
    "    tf.random.set_seed(42)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                  loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# ============ LOAD DATA (SATU EXCEL) ============\n",
    "if not os.path.exists(path_file_input):\n",
    "    raise FileNotFoundError(f\"File tidak ditemukan: {path_file_input}\")\n",
    "\n",
    "df = pd.read_excel(path_file_input)\n",
    "if 'Harga (Rp)' not in df.columns:\n",
    "    raise KeyError(f\"Kolom 'Harga (Rp)' tidak ditemukan di file {path_file_input}\")\n",
    "\n",
    "raw_data = df['Harga (Rp)'].values.reshape(-1, 1)\n",
    "print(f\"✓ Data: {path_file_input}\")\n",
    "print(f\"✓ Jumlah baris asli (raw): {len(raw_data)}\")\n",
    "\n",
    "region_name = os.path.basename(path_file_input).replace(\"Data_Clean_\", \"\").replace(\".xlsx\", \"\")\n",
    "\n",
    "# ============ WINDOW DI SKALA ASLI ============\n",
    "X_full_raw, Y_full_raw = create_sliding_window(raw_data, FIXED_WINDOW_SIZE)\n",
    "print(f\"✓ Sampel window: {len(X_full_raw)} (window={FIXED_WINDOW_SIZE})\")\n",
    "train_size = int(len(X_full_raw) * 0.8)\n",
    "y_test_orig = Y_full_raw[train_size:]  # uji di skala asli\n",
    "\n",
    "# ============ SCALER FIT HANYA TRAIN (ANTI-LEAKAGE) ============\n",
    "raw_train_segment = raw_data[:train_size + FIXED_WINDOW_SIZE]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(raw_train_segment)\n",
    "scaled_data = scaler.transform(raw_data)\n",
    "print(\"✓ Data ternormalisasi (0-1).\")\n",
    "\n",
    "# ============ WINDOWING PADA DATA SCALED ============\n",
    "X_full_scaled, Y_full_scaled = create_sliding_window(scaled_data, FIXED_WINDOW_SIZE)\n",
    "X_full_scaled = X_full_scaled.reshape(X_full_scaled.shape[0], X_full_scaled.shape[1], 1)\n",
    "\n",
    "X_train_all, X_test = X_full_scaled[:train_size], X_full_scaled[train_size:]\n",
    "y_train_all = Y_full_scaled[:train_size]\n",
    "\n",
    "# Validasi tail dari TRAIN\n",
    "val_cut = int(len(X_train_all) * (1 - VAL_RATIO))\n",
    "X_train, X_val = X_train_all[:val_cut], X_train_all[val_cut:]\n",
    "y_train, y_val = y_train_all[:val_cut], y_train_all[val_cut:]\n",
    "\n",
    "print(f\"[Info] Total: {len(X_full_scaled)} | Train: {len(X_train_all)} | Val: {len(X_val)} | Test: {len(X_test)}\")\n",
    "\n",
    "# ============ TRAINING DENGAN KONFIG TETAP ============\n",
    "reset_seeds()\n",
    "model = build_model_lstm((X_train.shape[1], 1))\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=FIXED_EPOCH,\n",
    "    batch_size=FIXED_BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=0,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history.get('val_loss', None)\n",
    "last_loss = float(train_loss[-1])\n",
    "last_val_loss = float(val_loss[-1]) if val_loss is not None else None\n",
    "best_epoch = int(np.argmin(val_loss) + 1) if val_loss is not None else int(np.argmin(train_loss) + 1)\n",
    "best_val = float(np.min(val_loss)) if val_loss is not None else float(np.min(train_loss))\n",
    "\n",
    "print(f\"   -> Selesai epoch : {FIXED_EPOCH}\")\n",
    "print(f\"   -> Best epoch    : {best_epoch} (val_loss={best_val:.6f})\")\n",
    "print(f\"   -> Last loss     : {last_loss:.6f}\" + (f\" | Last val_loss : {last_val_loss:.6f}\" if last_val_loss is not None else \"\"))\n",
    "\n",
    "# ============ EVALUASI DI TEST (DENORMALIZED) ============\n",
    "predictions_scaled = model.predict(X_test, verbose=0)\n",
    "predictions_real = scaler.inverse_transform(predictions_scaled)\n",
    "mape = mean_absolute_percentage_error(y_test_orig.ravel(), predictions_real.ravel()) * 100\n",
    "print(f\"   -> MAPE          : {mape:.4f}%\")\n",
    "\n",
    "# ============ OUTPUT ============\n",
    "region_out_dir = os.path.join(output_root, f\"{region_name}_w{FIXED_WINDOW_SIZE}_e{FIXED_EPOCH}_b{FIXED_BATCH_SIZE}\")\n",
    "os.makedirs(region_out_dir, exist_ok=True)\n",
    "\n",
    "# Simpan MODEL (.h5) dan SCALER (.pkl) + metadata\n",
    "model_path = os.path.join(region_out_dir, f\"{region_name}_model_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}_DO{DROPOUT_RATE}.h5\")\n",
    "scaler_path = os.path.join(region_out_dir, f\"{region_name}_scaler_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}_DO{DROPOUT_RATE}.pkl\")\n",
    "meta_path = os.path.join(region_out_dir, f\"{region_name}_metadata.json\")\n",
    "\n",
    "# Simpan model\n",
    "model.save(model_path)\n",
    "print(f\"   ✓ Model disimpan: {model_path}\")\n",
    "\n",
    "# Simpan scaler\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f\"   ✓ Scaler disimpan: {scaler_path}\")\n",
    "\n",
    "# Simpan metadata konfigurasi dan metrik\n",
    "metadata = {\n",
    "    \"region\": region_name,\n",
    "    \"window_size\": int(FIXED_WINDOW_SIZE),\n",
    "    \"epoch\": int(FIXED_EPOCH),\n",
    "    \"batch_size\": int(FIXED_BATCH_SIZE),\n",
    "    \"dropout_rate\": float(DROPOUT_RATE),\n",
    "    \"learning_rate\": float(LEARNING_RATE),\n",
    "    \"val_ratio\": float(VAL_RATIO),\n",
    "    \"train_samples\": int(len(X_train_all)),\n",
    "    \"val_samples\": int(len(X_val)),\n",
    "    \"test_samples\": int(len(X_test)),\n",
    "    \"best_epoch_val\": int(best_epoch),\n",
    "    \"best_val_loss\": float(best_val),\n",
    "    \"last_loss\": float(last_loss),\n",
    "    \"last_val_loss\": float(last_val_loss) if last_val_loss is not None else None,\n",
    "    \"mape_test_percent\": float(mape)\n",
    "}\n",
    "with open(meta_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "print(f\"   ✓ Metadata disimpan: {meta_path}\")\n",
    "\n",
    "# Plot Actual vs Predicted\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(y_test_orig, label='Actual (Real Data)')\n",
    "plt.plot(predictions_real, label='Predicted (Denormalized)')\n",
    "plt.title(f'{region_name} | W{FIXED_WINDOW_SIZE} E{FIXED_EPOCH} B{FIXED_BATCH_SIZE} DO{DROPOUT_RATE}')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Harga')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plot_path = os.path.join(region_out_dir, f\"{region_name}_Plot.png\")\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"   ✓ Plot disimpan: {plot_path}\")\n",
    "\n",
    "# Excel per-baris\n",
    "y_test_safe = np.where(y_test_orig.flatten() == 0, np.finfo(float).eps, y_test_orig.flatten())\n",
    "err_pct = np.abs((y_test_orig.flatten() - predictions_real.flatten()) / y_test_safe) * 100\n",
    "out_df = pd.DataFrame({\n",
    "    'Actual (Real)': y_test_orig.flatten(),\n",
    "    'Predicted (Real)': predictions_real.flatten(),\n",
    "    'Selisih': (y_test_orig.flatten() - predictions_real.flatten()),\n",
    "    'Error (%)': err_pct\n",
    "})\n",
    "excel_path = os.path.join(region_out_dir, f\"{region_name}_Prediksi_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "out_df.to_excel(excel_path, index=False)\n",
    "print(f\"   ✓ Prediksi disimpan: {excel_path}\")\n",
    "\n",
    "# Ringkasan singkat\n",
    "summary = pd.DataFrame([{\n",
    "    'Region': region_name,\n",
    "    'Window Size': int(FIXED_WINDOW_SIZE),\n",
    "    'Epoch': int(FIXED_EPOCH),\n",
    "    'Batch Size': int(FIXED_BATCH_SIZE),\n",
    "    'Dropout': float(DROPOUT_RATE),\n",
    "    'Best Epoch (val)': int(best_epoch),\n",
    "    'Best Val Loss': float(best_val),\n",
    "    'Last Loss': float(last_loss),\n",
    "    'Last Val Loss': float(last_val_loss) if last_val_loss is not None else None,\n",
    "    'MAPE (%)': float(mape)\n",
    "}])\n",
    "summary_path = os.path.join(region_out_dir, f\"{region_name}_Summary_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "summary.to_excel(summary_path, index=False)\n",
    "print(f\"   ✓ Ringkasan disimpan: {summary_path}\")\n",
    "\n",
    "print(\"\\nSelesai untuk file ini.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ec38d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data: E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Jember.xlsx\n",
      "✓ Jumlah baris asli (raw): 1043\n",
      "✓ Sampel window: 1036 (window=7)\n",
      "✓ Data ternormalisasi (0-1).\n",
      "[Info] Total: 1036 | Train: 828 | Val: 83 | Test: 208\n",
      "   -> Selesai epoch : 114\n",
      "   -> Best epoch    : 113 (val_loss=0.000323)\n",
      "   -> Last loss     : 0.000594 | Last val_loss : 0.000337\n",
      "   -> MAPE          : 4.0159%\n",
      "   ✓ Model disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Jember_w7_e114_b64\\Jember_model_W7_E114_B64_DO0.2.h5\n",
      "   ✓ Scaler disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Jember_w7_e114_b64\\Jember_scaler_W7_E114_B64_DO0.2.pkl\n",
      "   ✓ Metadata disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Jember_w7_e114_b64\\Jember_metadata.json\n",
      "   ✓ Plot disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Jember_w7_e114_b64\\Jember_Plot.png\n",
      "   ✓ Prediksi disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Jember_w7_e114_b64\\Jember_Prediksi_W7_E114_B64.xlsx\n",
      "   ✓ Ringkasan disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Jember_w7_e114_b64\\Jember_Summary_W7_E114_B64.xlsx\n",
      "\n",
      "Selesai untuk file ini.\n"
     ]
    }
   ],
   "source": [
    "#JEMBER\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# ============ SEEDS ============\n",
    "def reset_seeds():\n",
    "    np.random.seed(42)\n",
    "    python_random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "reset_seeds()\n",
    "\n",
    "# ============ KONFIG TETAP (HASIL TERBAIK) ============\n",
    "FIXED_WINDOW_SIZE = 7\n",
    "FIXED_EPOCH = 114\n",
    "FIXED_BATCH_SIZE = 64\n",
    "VAL_RATIO = 0.1\n",
    "DROPOUT_RATE = 0.2\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# ============ PATH FILE (GANTI PER WILAYAH) ============\n",
    "path_file_input = r\"E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Jember.xlsx\"\n",
    "output_root = r\"E:\\SKRIPSI 2025\\dataset\\FINAL\"\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "# ============ UTIL ============\n",
    "def create_sliding_window(dataset, window_size):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - window_size):\n",
    "        X.append(dataset[i:(i + window_size), 0])\n",
    "        Y.append(dataset[i + window_size, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def build_model_lstm(input_shape):\n",
    "    tf.random.set_seed(42)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                  loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# ============ LOAD DATA (SATU EXCEL) ============\n",
    "if not os.path.exists(path_file_input):\n",
    "    raise FileNotFoundError(f\"File tidak ditemukan: {path_file_input}\")\n",
    "\n",
    "df = pd.read_excel(path_file_input)\n",
    "if 'Harga (Rp)' not in df.columns:\n",
    "    raise KeyError(f\"Kolom 'Harga (Rp)' tidak ditemukan di file {path_file_input}\")\n",
    "\n",
    "raw_data = df['Harga (Rp)'].values.reshape(-1, 1)\n",
    "print(f\"✓ Data: {path_file_input}\")\n",
    "print(f\"✓ Jumlah baris asli (raw): {len(raw_data)}\")\n",
    "\n",
    "region_name = os.path.basename(path_file_input).replace(\"Data_Clean_\", \"\").replace(\".xlsx\", \"\")\n",
    "\n",
    "# ============ WINDOW DI SKALA ASLI ============\n",
    "X_full_raw, Y_full_raw = create_sliding_window(raw_data, FIXED_WINDOW_SIZE)\n",
    "print(f\"✓ Sampel window: {len(X_full_raw)} (window={FIXED_WINDOW_SIZE})\")\n",
    "train_size = int(len(X_full_raw) * 0.8)\n",
    "y_test_orig = Y_full_raw[train_size:]  # uji di skala asli\n",
    "\n",
    "# ============ SCALER FIT HANYA TRAIN (ANTI-LEAKAGE) ============\n",
    "raw_train_segment = raw_data[:train_size + FIXED_WINDOW_SIZE]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(raw_train_segment)\n",
    "scaled_data = scaler.transform(raw_data)\n",
    "print(\"✓ Data ternormalisasi (0-1).\")\n",
    "\n",
    "# ============ WINDOWING PADA DATA SCALED ============\n",
    "X_full_scaled, Y_full_scaled = create_sliding_window(scaled_data, FIXED_WINDOW_SIZE)\n",
    "X_full_scaled = X_full_scaled.reshape(X_full_scaled.shape[0], X_full_scaled.shape[1], 1)\n",
    "\n",
    "X_train_all, X_test = X_full_scaled[:train_size], X_full_scaled[train_size:]\n",
    "y_train_all = Y_full_scaled[:train_size]\n",
    "\n",
    "# Validasi tail dari TRAIN\n",
    "val_cut = int(len(X_train_all) * (1 - VAL_RATIO))\n",
    "X_train, X_val = X_train_all[:val_cut], X_train_all[val_cut:]\n",
    "y_train, y_val = y_train_all[:val_cut], y_train_all[val_cut:]\n",
    "\n",
    "print(f\"[Info] Total: {len(X_full_scaled)} | Train: {len(X_train_all)} | Val: {len(X_val)} | Test: {len(X_test)}\")\n",
    "\n",
    "# ============ TRAINING DENGAN KONFIG TETAP ============\n",
    "reset_seeds()\n",
    "model = build_model_lstm((X_train.shape[1], 1))\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=FIXED_EPOCH,\n",
    "    batch_size=FIXED_BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=0,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history.get('val_loss', None)\n",
    "last_loss = float(train_loss[-1])\n",
    "last_val_loss = float(val_loss[-1]) if val_loss is not None else None\n",
    "best_epoch = int(np.argmin(val_loss) + 1) if val_loss is not None else int(np.argmin(train_loss) + 1)\n",
    "best_val = float(np.min(val_loss)) if val_loss is not None else float(np.min(train_loss))\n",
    "\n",
    "print(f\"   -> Selesai epoch : {FIXED_EPOCH}\")\n",
    "print(f\"   -> Best epoch    : {best_epoch} (val_loss={best_val:.6f})\")\n",
    "print(f\"   -> Last loss     : {last_loss:.6f}\" + (f\" | Last val_loss : {last_val_loss:.6f}\" if last_val_loss is not None else \"\"))\n",
    "\n",
    "# ============ EVALUASI DI TEST (DENORMALIZED) ============\n",
    "predictions_scaled = model.predict(X_test, verbose=0)\n",
    "predictions_real = scaler.inverse_transform(predictions_scaled)\n",
    "mape = mean_absolute_percentage_error(y_test_orig.ravel(), predictions_real.ravel()) * 100\n",
    "print(f\"   -> MAPE          : {mape:.4f}%\")\n",
    "\n",
    "# ============ OUTPUT ============\n",
    "region_out_dir = os.path.join(output_root, f\"{region_name}_w{FIXED_WINDOW_SIZE}_e{FIXED_EPOCH}_b{FIXED_BATCH_SIZE}\")\n",
    "os.makedirs(region_out_dir, exist_ok=True)\n",
    "\n",
    "# Simpan MODEL (.h5) dan SCALER (.pkl) + metadata\n",
    "model_path = os.path.join(region_out_dir, f\"{region_name}_model_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}_DO{DROPOUT_RATE}.h5\")\n",
    "scaler_path = os.path.join(region_out_dir, f\"{region_name}_scaler_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}_DO{DROPOUT_RATE}.pkl\")\n",
    "meta_path = os.path.join(region_out_dir, f\"{region_name}_metadata.json\")\n",
    "\n",
    "# Simpan model\n",
    "model.save(model_path)\n",
    "print(f\"   ✓ Model disimpan: {model_path}\")\n",
    "\n",
    "# Simpan scaler\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f\"   ✓ Scaler disimpan: {scaler_path}\")\n",
    "\n",
    "# Simpan metadata konfigurasi dan metrik\n",
    "metadata = {\n",
    "    \"region\": region_name,\n",
    "    \"window_size\": int(FIXED_WINDOW_SIZE),\n",
    "    \"epoch\": int(FIXED_EPOCH),\n",
    "    \"batch_size\": int(FIXED_BATCH_SIZE),\n",
    "    \"dropout_rate\": float(DROPOUT_RATE),\n",
    "    \"learning_rate\": float(LEARNING_RATE),\n",
    "    \"val_ratio\": float(VAL_RATIO),\n",
    "    \"train_samples\": int(len(X_train_all)),\n",
    "    \"val_samples\": int(len(X_val)),\n",
    "    \"test_samples\": int(len(X_test)),\n",
    "    \"best_epoch_val\": int(best_epoch),\n",
    "    \"best_val_loss\": float(best_val),\n",
    "    \"last_loss\": float(last_loss),\n",
    "    \"last_val_loss\": float(last_val_loss) if last_val_loss is not None else None,\n",
    "    \"mape_test_percent\": float(mape)\n",
    "}\n",
    "with open(meta_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "print(f\"   ✓ Metadata disimpan: {meta_path}\")\n",
    "\n",
    "# Plot Actual vs Predicted\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(y_test_orig, label='Actual (Real Data)')\n",
    "plt.plot(predictions_real, label='Predicted (Denormalized)')\n",
    "plt.title(f'{region_name} | W{FIXED_WINDOW_SIZE} E{FIXED_EPOCH} B{FIXED_BATCH_SIZE} DO{DROPOUT_RATE}')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Harga')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plot_path = os.path.join(region_out_dir, f\"{region_name}_Plot.png\")\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"   ✓ Plot disimpan: {plot_path}\")\n",
    "\n",
    "# Excel per-baris\n",
    "y_test_safe = np.where(y_test_orig.flatten() == 0, np.finfo(float).eps, y_test_orig.flatten())\n",
    "err_pct = np.abs((y_test_orig.flatten() - predictions_real.flatten()) / y_test_safe) * 100\n",
    "out_df = pd.DataFrame({\n",
    "    'Actual (Real)': y_test_orig.flatten(),\n",
    "    'Predicted (Real)': predictions_real.flatten(),\n",
    "    'Selisih': (y_test_orig.flatten() - predictions_real.flatten()),\n",
    "    'Error (%)': err_pct\n",
    "})\n",
    "excel_path = os.path.join(region_out_dir, f\"{region_name}_Prediksi_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "out_df.to_excel(excel_path, index=False)\n",
    "print(f\"   ✓ Prediksi disimpan: {excel_path}\")\n",
    "\n",
    "# Ringkasan singkat\n",
    "summary = pd.DataFrame([{\n",
    "    'Region': region_name,\n",
    "    'Window Size': int(FIXED_WINDOW_SIZE),\n",
    "    'Epoch': int(FIXED_EPOCH),\n",
    "    'Batch Size': int(FIXED_BATCH_SIZE),\n",
    "    'Dropout': float(DROPOUT_RATE),\n",
    "    'Best Epoch (val)': int(best_epoch),\n",
    "    'Best Val Loss': float(best_val),\n",
    "    'Last Loss': float(last_loss),\n",
    "    'Last Val Loss': float(last_val_loss) if last_val_loss is not None else None,\n",
    "    'MAPE (%)': float(mape)\n",
    "}])\n",
    "summary_path = os.path.join(region_out_dir, f\"{region_name}_Summary_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "summary.to_excel(summary_path, index=False)\n",
    "print(f\"   ✓ Ringkasan disimpan: {summary_path}\")\n",
    "\n",
    "print(\"\\nSelesai untuk file ini.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30303197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data: E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Kediri.xlsx\n",
      "✓ Jumlah baris asli (raw): 1043\n",
      "✓ Sampel window: 1036 (window=7)\n",
      "✓ Data ternormalisasi (0-1).\n",
      "[Info] Total: 1036 | Train: 828 | Val: 83 | Test: 208\n",
      "   -> Selesai epoch : 114\n",
      "   -> Best epoch    : 113 (val_loss=0.000207)\n",
      "   -> Last loss     : 0.000798 | Last val_loss : 0.000226\n",
      "   -> MAPE          : 2.2610%\n",
      "   ✓ Model disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Kediri_w7_e114_b64\\Kediri_model_W7_E114_B64_DO0.2.h5\n",
      "   ✓ Scaler disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Kediri_w7_e114_b64\\Kediri_scaler_W7_E114_B64_DO0.2.pkl\n",
      "   ✓ Metadata disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Kediri_w7_e114_b64\\Kediri_metadata.json\n",
      "   ✓ Plot disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Kediri_w7_e114_b64\\Kediri_Plot.png\n",
      "   ✓ Prediksi disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Kediri_w7_e114_b64\\Kediri_Prediksi_W7_E114_B64.xlsx\n",
      "   ✓ Ringkasan disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Kediri_w7_e114_b64\\Kediri_Summary_W7_E114_B64.xlsx\n",
      "\n",
      "Selesai untuk file ini.\n"
     ]
    }
   ],
   "source": [
    "#KEDIRI\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# ============ SEEDS ============\n",
    "def reset_seeds():\n",
    "    np.random.seed(42)\n",
    "    python_random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "reset_seeds()\n",
    "\n",
    "# ============ KONFIG TETAP (HASIL TERBAIK) ============\n",
    "FIXED_WINDOW_SIZE = 7\n",
    "FIXED_EPOCH = 114\n",
    "FIXED_BATCH_SIZE = 64\n",
    "VAL_RATIO = 0.1\n",
    "DROPOUT_RATE = 0.2\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# ============ PATH FILE (GANTI PER WILAYAH) ============\n",
    "path_file_input = r\"E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Kediri.xlsx\"\n",
    "output_root = r\"E:\\SKRIPSI 2025\\dataset\\FINAL\"\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "# ============ UTIL ============\n",
    "def create_sliding_window(dataset, window_size):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - window_size):\n",
    "        X.append(dataset[i:(i + window_size), 0])\n",
    "        Y.append(dataset[i + window_size, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def build_model_lstm(input_shape):\n",
    "    tf.random.set_seed(42)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                  loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# ============ LOAD DATA (SATU EXCEL) ============\n",
    "if not os.path.exists(path_file_input):\n",
    "    raise FileNotFoundError(f\"File tidak ditemukan: {path_file_input}\")\n",
    "\n",
    "df = pd.read_excel(path_file_input)\n",
    "if 'Harga (Rp)' not in df.columns:\n",
    "    raise KeyError(f\"Kolom 'Harga (Rp)' tidak ditemukan di file {path_file_input}\")\n",
    "\n",
    "raw_data = df['Harga (Rp)'].values.reshape(-1, 1)\n",
    "print(f\"✓ Data: {path_file_input}\")\n",
    "print(f\"✓ Jumlah baris asli (raw): {len(raw_data)}\")\n",
    "\n",
    "region_name = os.path.basename(path_file_input).replace(\"Data_Clean_\", \"\").replace(\".xlsx\", \"\")\n",
    "\n",
    "# ============ WINDOW DI SKALA ASLI ============\n",
    "X_full_raw, Y_full_raw = create_sliding_window(raw_data, FIXED_WINDOW_SIZE)\n",
    "print(f\"✓ Sampel window: {len(X_full_raw)} (window={FIXED_WINDOW_SIZE})\")\n",
    "train_size = int(len(X_full_raw) * 0.8)\n",
    "y_test_orig = Y_full_raw[train_size:]  # uji di skala asli\n",
    "\n",
    "# ============ SCALER FIT HANYA TRAIN (ANTI-LEAKAGE) ============\n",
    "raw_train_segment = raw_data[:train_size + FIXED_WINDOW_SIZE]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(raw_train_segment)\n",
    "scaled_data = scaler.transform(raw_data)\n",
    "print(\"✓ Data ternormalisasi (0-1).\")\n",
    "\n",
    "# ============ WINDOWING PADA DATA SCALED ============\n",
    "X_full_scaled, Y_full_scaled = create_sliding_window(scaled_data, FIXED_WINDOW_SIZE)\n",
    "X_full_scaled = X_full_scaled.reshape(X_full_scaled.shape[0], X_full_scaled.shape[1], 1)\n",
    "\n",
    "X_train_all, X_test = X_full_scaled[:train_size], X_full_scaled[train_size:]\n",
    "y_train_all = Y_full_scaled[:train_size]\n",
    "\n",
    "# Validasi tail dari TRAIN\n",
    "val_cut = int(len(X_train_all) * (1 - VAL_RATIO))\n",
    "X_train, X_val = X_train_all[:val_cut], X_train_all[val_cut:]\n",
    "y_train, y_val = y_train_all[:val_cut], y_train_all[val_cut:]\n",
    "\n",
    "print(f\"[Info] Total: {len(X_full_scaled)} | Train: {len(X_train_all)} | Val: {len(X_val)} | Test: {len(X_test)}\")\n",
    "\n",
    "# ============ TRAINING DENGAN KONFIG TETAP ============\n",
    "reset_seeds()\n",
    "model = build_model_lstm((X_train.shape[1], 1))\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=FIXED_EPOCH,\n",
    "    batch_size=FIXED_BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=0,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history.get('val_loss', None)\n",
    "last_loss = float(train_loss[-1])\n",
    "last_val_loss = float(val_loss[-1]) if val_loss is not None else None\n",
    "best_epoch = int(np.argmin(val_loss) + 1) if val_loss is not None else int(np.argmin(train_loss) + 1)\n",
    "best_val = float(np.min(val_loss)) if val_loss is not None else float(np.min(train_loss))\n",
    "\n",
    "print(f\"   -> Selesai epoch : {FIXED_EPOCH}\")\n",
    "print(f\"   -> Best epoch    : {best_epoch} (val_loss={best_val:.6f})\")\n",
    "print(f\"   -> Last loss     : {last_loss:.6f}\" + (f\" | Last val_loss : {last_val_loss:.6f}\" if last_val_loss is not None else \"\"))\n",
    "\n",
    "# ============ EVALUASI DI TEST (DENORMALIZED) ============\n",
    "predictions_scaled = model.predict(X_test, verbose=0)\n",
    "predictions_real = scaler.inverse_transform(predictions_scaled)\n",
    "mape = mean_absolute_percentage_error(y_test_orig.ravel(), predictions_real.ravel()) * 100\n",
    "print(f\"   -> MAPE          : {mape:.4f}%\")\n",
    "\n",
    "# ============ OUTPUT ============\n",
    "region_out_dir = os.path.join(output_root, f\"{region_name}_w{FIXED_WINDOW_SIZE}_e{FIXED_EPOCH}_b{FIXED_BATCH_SIZE}\")\n",
    "os.makedirs(region_out_dir, exist_ok=True)\n",
    "\n",
    "# Simpan MODEL (.h5) dan SCALER (.pkl) + metadata\n",
    "model_path = os.path.join(region_out_dir, f\"{region_name}_model_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}_DO{DROPOUT_RATE}.h5\")\n",
    "scaler_path = os.path.join(region_out_dir, f\"{region_name}_scaler_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}_DO{DROPOUT_RATE}.pkl\")\n",
    "meta_path = os.path.join(region_out_dir, f\"{region_name}_metadata.json\")\n",
    "\n",
    "# Simpan model\n",
    "model.save(model_path)\n",
    "print(f\"   ✓ Model disimpan: {model_path}\")\n",
    "\n",
    "# Simpan scaler\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f\"   ✓ Scaler disimpan: {scaler_path}\")\n",
    "\n",
    "# Simpan metadata konfigurasi dan metrik\n",
    "metadata = {\n",
    "    \"region\": region_name,\n",
    "    \"window_size\": int(FIXED_WINDOW_SIZE),\n",
    "    \"epoch\": int(FIXED_EPOCH),\n",
    "    \"batch_size\": int(FIXED_BATCH_SIZE),\n",
    "    \"dropout_rate\": float(DROPOUT_RATE),\n",
    "    \"learning_rate\": float(LEARNING_RATE),\n",
    "    \"val_ratio\": float(VAL_RATIO),\n",
    "    \"train_samples\": int(len(X_train_all)),\n",
    "    \"val_samples\": int(len(X_val)),\n",
    "    \"test_samples\": int(len(X_test)),\n",
    "    \"best_epoch_val\": int(best_epoch),\n",
    "    \"best_val_loss\": float(best_val),\n",
    "    \"last_loss\": float(last_loss),\n",
    "    \"last_val_loss\": float(last_val_loss) if last_val_loss is not None else None,\n",
    "    \"mape_test_percent\": float(mape)\n",
    "}\n",
    "with open(meta_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "print(f\"   ✓ Metadata disimpan: {meta_path}\")\n",
    "\n",
    "# Plot Actual vs Predicted\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(y_test_orig, label='Actual (Real Data)')\n",
    "plt.plot(predictions_real, label='Predicted (Denormalized)')\n",
    "plt.title(f'{region_name} | W{FIXED_WINDOW_SIZE} E{FIXED_EPOCH} B{FIXED_BATCH_SIZE} DO{DROPOUT_RATE}')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Harga')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plot_path = os.path.join(region_out_dir, f\"{region_name}_Plot.png\")\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"   ✓ Plot disimpan: {plot_path}\")\n",
    "\n",
    "# Excel per-baris\n",
    "y_test_safe = np.where(y_test_orig.flatten() == 0, np.finfo(float).eps, y_test_orig.flatten())\n",
    "err_pct = np.abs((y_test_orig.flatten() - predictions_real.flatten()) / y_test_safe) * 100\n",
    "out_df = pd.DataFrame({\n",
    "    'Actual (Real)': y_test_orig.flatten(),\n",
    "    'Predicted (Real)': predictions_real.flatten(),\n",
    "    'Selisih': (y_test_orig.flatten() - predictions_real.flatten()),\n",
    "    'Error (%)': err_pct\n",
    "})\n",
    "excel_path = os.path.join(region_out_dir, f\"{region_name}_Prediksi_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "out_df.to_excel(excel_path, index=False)\n",
    "print(f\"   ✓ Prediksi disimpan: {excel_path}\")\n",
    "\n",
    "# Ringkasan singkat\n",
    "summary = pd.DataFrame([{\n",
    "    'Region': region_name,\n",
    "    'Window Size': int(FIXED_WINDOW_SIZE),\n",
    "    'Epoch': int(FIXED_EPOCH),\n",
    "    'Batch Size': int(FIXED_BATCH_SIZE),\n",
    "    'Dropout': float(DROPOUT_RATE),\n",
    "    'Best Epoch (val)': int(best_epoch),\n",
    "    'Best Val Loss': float(best_val),\n",
    "    'Last Loss': float(last_loss),\n",
    "    'Last Val Loss': float(last_val_loss) if last_val_loss is not None else None,\n",
    "    'MAPE (%)': float(mape)\n",
    "}])\n",
    "summary_path = os.path.join(region_out_dir, f\"{region_name}_Summary_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "summary.to_excel(summary_path, index=False)\n",
    "print(f\"   ✓ Ringkasan disimpan: {summary_path}\")\n",
    "\n",
    "print(\"\\nSelesai untuk file ini.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b795af80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data: E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Madiun.xlsx\n",
      "✓ Jumlah baris asli (raw): 1043\n",
      "✓ Sampel window: 1036 (window=7)\n",
      "✓ Data ternormalisasi (0-1).\n",
      "[Info] Total: 1036 | Train: 828 | Val: 83 | Test: 208\n",
      "   -> Selesai epoch : 114\n",
      "   -> Best epoch    : 114 (val_loss=0.000330)\n",
      "   -> Last loss     : 0.000922 | Last val_loss : 0.000330\n",
      "   -> MAPE          : 2.7484%\n",
      "   ✓ Model disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Madiun_w7_e114_b64\\Madiun_model_W7_E114_B64_DO0.2.h5\n",
      "   ✓ Scaler disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Madiun_w7_e114_b64\\Madiun_scaler_W7_E114_B64_DO0.2.pkl\n",
      "   ✓ Metadata disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Madiun_w7_e114_b64\\Madiun_metadata.json\n",
      "   ✓ Plot disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Madiun_w7_e114_b64\\Madiun_Plot.png\n",
      "   ✓ Prediksi disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Madiun_w7_e114_b64\\Madiun_Prediksi_W7_E114_B64.xlsx\n",
      "   ✓ Ringkasan disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Madiun_w7_e114_b64\\Madiun_Summary_W7_E114_B64.xlsx\n",
      "\n",
      "Selesai untuk file ini.\n"
     ]
    }
   ],
   "source": [
    "#MADIUN\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# ============ SEEDS ============\n",
    "def reset_seeds():\n",
    "    np.random.seed(42)\n",
    "    python_random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "reset_seeds()\n",
    "\n",
    "# ============ KONFIG TETAP (HASIL TERBAIK) ============\n",
    "FIXED_WINDOW_SIZE = 7\n",
    "FIXED_EPOCH = 114\n",
    "FIXED_BATCH_SIZE = 64\n",
    "VAL_RATIO = 0.1\n",
    "DROPOUT_RATE = 0.2\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# ============ PATH FILE (GANTI PER WILAYAH) ============\n",
    "path_file_input = r\"E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Madiun.xlsx\"\n",
    "output_root = r\"E:\\SKRIPSI 2025\\dataset\\FINAL\"\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "# ============ UTIL ============\n",
    "def create_sliding_window(dataset, window_size):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - window_size):\n",
    "        X.append(dataset[i:(i + window_size), 0])\n",
    "        Y.append(dataset[i + window_size, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def build_model_lstm(input_shape):\n",
    "    tf.random.set_seed(42)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                  loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# ============ LOAD DATA (SATU EXCEL) ============\n",
    "if not os.path.exists(path_file_input):\n",
    "    raise FileNotFoundError(f\"File tidak ditemukan: {path_file_input}\")\n",
    "\n",
    "df = pd.read_excel(path_file_input)\n",
    "if 'Harga (Rp)' not in df.columns:\n",
    "    raise KeyError(f\"Kolom 'Harga (Rp)' tidak ditemukan di file {path_file_input}\")\n",
    "\n",
    "raw_data = df['Harga (Rp)'].values.reshape(-1, 1)\n",
    "print(f\"✓ Data: {path_file_input}\")\n",
    "print(f\"✓ Jumlah baris asli (raw): {len(raw_data)}\")\n",
    "\n",
    "region_name = os.path.basename(path_file_input).replace(\"Data_Clean_\", \"\").replace(\".xlsx\", \"\")\n",
    "\n",
    "# ============ WINDOW DI SKALA ASLI ============\n",
    "X_full_raw, Y_full_raw = create_sliding_window(raw_data, FIXED_WINDOW_SIZE)\n",
    "print(f\"✓ Sampel window: {len(X_full_raw)} (window={FIXED_WINDOW_SIZE})\")\n",
    "train_size = int(len(X_full_raw) * 0.8)\n",
    "y_test_orig = Y_full_raw[train_size:]  # uji di skala asli\n",
    "\n",
    "# ============ SCALER FIT HANYA TRAIN (ANTI-LEAKAGE) ============\n",
    "raw_train_segment = raw_data[:train_size + FIXED_WINDOW_SIZE]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(raw_train_segment)\n",
    "scaled_data = scaler.transform(raw_data)\n",
    "print(\"✓ Data ternormalisasi (0-1).\")\n",
    "\n",
    "# ============ WINDOWING PADA DATA SCALED ============\n",
    "X_full_scaled, Y_full_scaled = create_sliding_window(scaled_data, FIXED_WINDOW_SIZE)\n",
    "X_full_scaled = X_full_scaled.reshape(X_full_scaled.shape[0], X_full_scaled.shape[1], 1)\n",
    "\n",
    "X_train_all, X_test = X_full_scaled[:train_size], X_full_scaled[train_size:]\n",
    "y_train_all = Y_full_scaled[:train_size]\n",
    "\n",
    "# Validasi tail dari TRAIN\n",
    "val_cut = int(len(X_train_all) * (1 - VAL_RATIO))\n",
    "X_train, X_val = X_train_all[:val_cut], X_train_all[val_cut:]\n",
    "y_train, y_val = y_train_all[:val_cut], y_train_all[val_cut:]\n",
    "\n",
    "print(f\"[Info] Total: {len(X_full_scaled)} | Train: {len(X_train_all)} | Val: {len(X_val)} | Test: {len(X_test)}\")\n",
    "\n",
    "# ============ TRAINING DENGAN KONFIG TETAP ============\n",
    "reset_seeds()\n",
    "model = build_model_lstm((X_train.shape[1], 1))\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=FIXED_EPOCH,\n",
    "    batch_size=FIXED_BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=0,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history.get('val_loss', None)\n",
    "last_loss = float(train_loss[-1])\n",
    "last_val_loss = float(val_loss[-1]) if val_loss is not None else None\n",
    "best_epoch = int(np.argmin(val_loss) + 1) if val_loss is not None else int(np.argmin(train_loss) + 1)\n",
    "best_val = float(np.min(val_loss)) if val_loss is not None else float(np.min(train_loss))\n",
    "\n",
    "print(f\"   -> Selesai epoch : {FIXED_EPOCH}\")\n",
    "print(f\"   -> Best epoch    : {best_epoch} (val_loss={best_val:.6f})\")\n",
    "print(f\"   -> Last loss     : {last_loss:.6f}\" + (f\" | Last val_loss : {last_val_loss:.6f}\" if last_val_loss is not None else \"\"))\n",
    "\n",
    "# ============ EVALUASI DI TEST (DENORMALIZED) ============\n",
    "predictions_scaled = model.predict(X_test, verbose=0)\n",
    "predictions_real = scaler.inverse_transform(predictions_scaled)\n",
    "mape = mean_absolute_percentage_error(y_test_orig.ravel(), predictions_real.ravel()) * 100\n",
    "print(f\"   -> MAPE          : {mape:.4f}%\")\n",
    "\n",
    "# ============ OUTPUT ============\n",
    "region_out_dir = os.path.join(output_root, f\"{region_name}_w{FIXED_WINDOW_SIZE}_e{FIXED_EPOCH}_b{FIXED_BATCH_SIZE}\")\n",
    "os.makedirs(region_out_dir, exist_ok=True)\n",
    "\n",
    "# Simpan MODEL (.h5) dan SCALER (.pkl) + metadata\n",
    "model_path = os.path.join(region_out_dir, f\"{region_name}_model_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}_DO{DROPOUT_RATE}.h5\")\n",
    "scaler_path = os.path.join(region_out_dir, f\"{region_name}_scaler_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}_DO{DROPOUT_RATE}.pkl\")\n",
    "meta_path = os.path.join(region_out_dir, f\"{region_name}_metadata.json\")\n",
    "\n",
    "# Simpan model\n",
    "model.save(model_path)\n",
    "print(f\"   ✓ Model disimpan: {model_path}\")\n",
    "\n",
    "# Simpan scaler\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f\"   ✓ Scaler disimpan: {scaler_path}\")\n",
    "\n",
    "# Simpan metadata konfigurasi dan metrik\n",
    "metadata = {\n",
    "    \"region\": region_name,\n",
    "    \"window_size\": int(FIXED_WINDOW_SIZE),\n",
    "    \"epoch\": int(FIXED_EPOCH),\n",
    "    \"batch_size\": int(FIXED_BATCH_SIZE),\n",
    "    \"dropout_rate\": float(DROPOUT_RATE),\n",
    "    \"learning_rate\": float(LEARNING_RATE),\n",
    "    \"val_ratio\": float(VAL_RATIO),\n",
    "    \"train_samples\": int(len(X_train_all)),\n",
    "    \"val_samples\": int(len(X_val)),\n",
    "    \"test_samples\": int(len(X_test)),\n",
    "    \"best_epoch_val\": int(best_epoch),\n",
    "    \"best_val_loss\": float(best_val),\n",
    "    \"last_loss\": float(last_loss),\n",
    "    \"last_val_loss\": float(last_val_loss) if last_val_loss is not None else None,\n",
    "    \"mape_test_percent\": float(mape)\n",
    "}\n",
    "with open(meta_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "print(f\"   ✓ Metadata disimpan: {meta_path}\")\n",
    "\n",
    "# Plot Actual vs Predicted\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(y_test_orig, label='Actual (Real Data)')\n",
    "plt.plot(predictions_real, label='Predicted (Denormalized)')\n",
    "plt.title(f'{region_name} | W{FIXED_WINDOW_SIZE} E{FIXED_EPOCH} B{FIXED_BATCH_SIZE} DO{DROPOUT_RATE}')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Harga')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plot_path = os.path.join(region_out_dir, f\"{region_name}_Plot.png\")\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"   ✓ Plot disimpan: {plot_path}\")\n",
    "\n",
    "# Excel per-baris\n",
    "y_test_safe = np.where(y_test_orig.flatten() == 0, np.finfo(float).eps, y_test_orig.flatten())\n",
    "err_pct = np.abs((y_test_orig.flatten() - predictions_real.flatten()) / y_test_safe) * 100\n",
    "out_df = pd.DataFrame({\n",
    "    'Actual (Real)': y_test_orig.flatten(),\n",
    "    'Predicted (Real)': predictions_real.flatten(),\n",
    "    'Selisih': (y_test_orig.flatten() - predictions_real.flatten()),\n",
    "    'Error (%)': err_pct\n",
    "})\n",
    "excel_path = os.path.join(region_out_dir, f\"{region_name}_Prediksi_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "out_df.to_excel(excel_path, index=False)\n",
    "print(f\"   ✓ Prediksi disimpan: {excel_path}\")\n",
    "\n",
    "# Ringkasan singkat\n",
    "summary = pd.DataFrame([{\n",
    "    'Region': region_name,\n",
    "    'Window Size': int(FIXED_WINDOW_SIZE),\n",
    "    'Epoch': int(FIXED_EPOCH),\n",
    "    'Batch Size': int(FIXED_BATCH_SIZE),\n",
    "    'Dropout': float(DROPOUT_RATE),\n",
    "    'Best Epoch (val)': int(best_epoch),\n",
    "    'Best Val Loss': float(best_val),\n",
    "    'Last Loss': float(last_loss),\n",
    "    'Last Val Loss': float(last_val_loss) if last_val_loss is not None else None,\n",
    "    'MAPE (%)': float(mape)\n",
    "}])\n",
    "summary_path = os.path.join(region_out_dir, f\"{region_name}_Summary_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "summary.to_excel(summary_path, index=False)\n",
    "print(f\"   ✓ Ringkasan disimpan: {summary_path}\")\n",
    "\n",
    "print(\"\\nSelesai untuk file ini.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaea593d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data: E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Malang.xlsx\n",
      "✓ Jumlah baris asli (raw): 1043\n",
      "✓ Sampel window: 1036 (window=7)\n",
      "✓ Data ternormalisasi (0-1).\n",
      "[Info] Total: 1036 | Train: 828 | Val: 83 | Test: 208\n",
      "   -> Selesai epoch : 114\n",
      "   -> Best epoch    : 105 (val_loss=0.000197)\n",
      "   -> Last loss     : 0.001020 | Last val_loss : 0.000407\n",
      "   -> MAPE          : 3.4254%\n",
      "   ✓ Model disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Malang_w7_e114_b64\\Malang_model_W7_E114_B64_DO0.2.h5\n",
      "   ✓ Scaler disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Malang_w7_e114_b64\\Malang_scaler_W7_E114_B64_DO0.2.pkl\n",
      "   ✓ Metadata disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Malang_w7_e114_b64\\Malang_metadata.json\n",
      "   ✓ Plot disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Malang_w7_e114_b64\\Malang_Plot.png\n",
      "   ✓ Prediksi disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Malang_w7_e114_b64\\Malang_Prediksi_W7_E114_B64.xlsx\n",
      "   ✓ Ringkasan disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Malang_w7_e114_b64\\Malang_Summary_W7_E114_B64.xlsx\n",
      "\n",
      "Selesai untuk file ini.\n"
     ]
    }
   ],
   "source": [
    "#MALANG\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# ============ SEEDS ============\n",
    "def reset_seeds():\n",
    "    np.random.seed(42)\n",
    "    python_random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "reset_seeds()\n",
    "\n",
    "# ============ KONFIG TETAP (HASIL TERBAIK) ============\n",
    "FIXED_WINDOW_SIZE = 7\n",
    "FIXED_EPOCH = 114\n",
    "FIXED_BATCH_SIZE = 64\n",
    "VAL_RATIO = 0.1\n",
    "DROPOUT_RATE = 0.2\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# ============ PATH FILE (GANTI PER WILAYAH) ============\n",
    "path_file_input = r\"E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Malang.xlsx\"\n",
    "output_root = r\"E:\\SKRIPSI 2025\\dataset\\FINAL\"\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "# ============ UTIL ============\n",
    "def create_sliding_window(dataset, window_size):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - window_size):\n",
    "        X.append(dataset[i:(i + window_size), 0])\n",
    "        Y.append(dataset[i + window_size, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def build_model_lstm(input_shape):\n",
    "    tf.random.set_seed(42)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                  loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# ============ LOAD DATA (SATU EXCEL) ============\n",
    "if not os.path.exists(path_file_input):\n",
    "    raise FileNotFoundError(f\"File tidak ditemukan: {path_file_input}\")\n",
    "\n",
    "df = pd.read_excel(path_file_input)\n",
    "if 'Harga (Rp)' not in df.columns:\n",
    "    raise KeyError(f\"Kolom 'Harga (Rp)' tidak ditemukan di file {path_file_input}\")\n",
    "\n",
    "raw_data = df['Harga (Rp)'].values.reshape(-1, 1)\n",
    "print(f\"✓ Data: {path_file_input}\")\n",
    "print(f\"✓ Jumlah baris asli (raw): {len(raw_data)}\")\n",
    "\n",
    "region_name = os.path.basename(path_file_input).replace(\"Data_Clean_\", \"\").replace(\".xlsx\", \"\")\n",
    "\n",
    "# ============ WINDOW DI SKALA ASLI ============\n",
    "X_full_raw, Y_full_raw = create_sliding_window(raw_data, FIXED_WINDOW_SIZE)\n",
    "print(f\"✓ Sampel window: {len(X_full_raw)} (window={FIXED_WINDOW_SIZE})\")\n",
    "train_size = int(len(X_full_raw) * 0.8)\n",
    "y_test_orig = Y_full_raw[train_size:]  # uji di skala asli\n",
    "\n",
    "# ============ SCALER FIT HANYA TRAIN (ANTI-LEAKAGE) ============\n",
    "raw_train_segment = raw_data[:train_size + FIXED_WINDOW_SIZE]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(raw_train_segment)\n",
    "scaled_data = scaler.transform(raw_data)\n",
    "print(\"✓ Data ternormalisasi (0-1).\")\n",
    "\n",
    "# ============ WINDOWING PADA DATA SCALED ============\n",
    "X_full_scaled, Y_full_scaled = create_sliding_window(scaled_data, FIXED_WINDOW_SIZE)\n",
    "X_full_scaled = X_full_scaled.reshape(X_full_scaled.shape[0], X_full_scaled.shape[1], 1)\n",
    "\n",
    "X_train_all, X_test = X_full_scaled[:train_size], X_full_scaled[train_size:]\n",
    "y_train_all = Y_full_scaled[:train_size]\n",
    "\n",
    "# Validasi tail dari TRAIN\n",
    "val_cut = int(len(X_train_all) * (1 - VAL_RATIO))\n",
    "X_train, X_val = X_train_all[:val_cut], X_train_all[val_cut:]\n",
    "y_train, y_val = y_train_all[:val_cut], y_train_all[val_cut:]\n",
    "\n",
    "print(f\"[Info] Total: {len(X_full_scaled)} | Train: {len(X_train_all)} | Val: {len(X_val)} | Test: {len(X_test)}\")\n",
    "\n",
    "# ============ TRAINING DENGAN KONFIG TETAP ============\n",
    "reset_seeds()\n",
    "model = build_model_lstm((X_train.shape[1], 1))\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=FIXED_EPOCH,\n",
    "    batch_size=FIXED_BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=0,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history.get('val_loss', None)\n",
    "last_loss = float(train_loss[-1])\n",
    "last_val_loss = float(val_loss[-1]) if val_loss is not None else None\n",
    "best_epoch = int(np.argmin(val_loss) + 1) if val_loss is not None else int(np.argmin(train_loss) + 1)\n",
    "best_val = float(np.min(val_loss)) if val_loss is not None else float(np.min(train_loss))\n",
    "\n",
    "print(f\"   -> Selesai epoch : {FIXED_EPOCH}\")\n",
    "print(f\"   -> Best epoch    : {best_epoch} (val_loss={best_val:.6f})\")\n",
    "print(f\"   -> Last loss     : {last_loss:.6f}\" + (f\" | Last val_loss : {last_val_loss:.6f}\" if last_val_loss is not None else \"\"))\n",
    "\n",
    "# ============ EVALUASI DI TEST (DENORMALIZED) ============\n",
    "predictions_scaled = model.predict(X_test, verbose=0)\n",
    "predictions_real = scaler.inverse_transform(predictions_scaled)\n",
    "mape = mean_absolute_percentage_error(y_test_orig.ravel(), predictions_real.ravel()) * 100\n",
    "print(f\"   -> MAPE          : {mape:.4f}%\")\n",
    "\n",
    "# ============ OUTPUT ============\n",
    "region_out_dir = os.path.join(output_root, f\"{region_name}_w{FIXED_WINDOW_SIZE}_e{FIXED_EPOCH}_b{FIXED_BATCH_SIZE}\")\n",
    "os.makedirs(region_out_dir, exist_ok=True)\n",
    "\n",
    "# Simpan MODEL (.h5) dan SCALER (.pkl) + metadata\n",
    "model_path = os.path.join(region_out_dir, f\"{region_name}_model_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}_DO{DROPOUT_RATE}.h5\")\n",
    "scaler_path = os.path.join(region_out_dir, f\"{region_name}_scaler_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}_DO{DROPOUT_RATE}.pkl\")\n",
    "meta_path = os.path.join(region_out_dir, f\"{region_name}_metadata.json\")\n",
    "\n",
    "# Simpan model\n",
    "model.save(model_path)\n",
    "print(f\"   ✓ Model disimpan: {model_path}\")\n",
    "\n",
    "# Simpan scaler\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f\"   ✓ Scaler disimpan: {scaler_path}\")\n",
    "\n",
    "# Simpan metadata konfigurasi dan metrik\n",
    "metadata = {\n",
    "    \"region\": region_name,\n",
    "    \"window_size\": int(FIXED_WINDOW_SIZE),\n",
    "    \"epoch\": int(FIXED_EPOCH),\n",
    "    \"batch_size\": int(FIXED_BATCH_SIZE),\n",
    "    \"dropout_rate\": float(DROPOUT_RATE),\n",
    "    \"learning_rate\": float(LEARNING_RATE),\n",
    "    \"val_ratio\": float(VAL_RATIO),\n",
    "    \"train_samples\": int(len(X_train_all)),\n",
    "    \"val_samples\": int(len(X_val)),\n",
    "    \"test_samples\": int(len(X_test)),\n",
    "    \"best_epoch_val\": int(best_epoch),\n",
    "    \"best_val_loss\": float(best_val),\n",
    "    \"last_loss\": float(last_loss),\n",
    "    \"last_val_loss\": float(last_val_loss) if last_val_loss is not None else None,\n",
    "    \"mape_test_percent\": float(mape)\n",
    "}\n",
    "with open(meta_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "print(f\"   ✓ Metadata disimpan: {meta_path}\")\n",
    "\n",
    "# Plot Actual vs Predicted\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(y_test_orig, label='Actual (Real Data)')\n",
    "plt.plot(predictions_real, label='Predicted (Denormalized)')\n",
    "plt.title(f'{region_name} | W{FIXED_WINDOW_SIZE} E{FIXED_EPOCH} B{FIXED_BATCH_SIZE} DO{DROPOUT_RATE}')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Harga')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plot_path = os.path.join(region_out_dir, f\"{region_name}_Plot.png\")\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"   ✓ Plot disimpan: {plot_path}\")\n",
    "\n",
    "# Excel per-baris\n",
    "y_test_safe = np.where(y_test_orig.flatten() == 0, np.finfo(float).eps, y_test_orig.flatten())\n",
    "err_pct = np.abs((y_test_orig.flatten() - predictions_real.flatten()) / y_test_safe) * 100\n",
    "out_df = pd.DataFrame({\n",
    "    'Actual (Real)': y_test_orig.flatten(),\n",
    "    'Predicted (Real)': predictions_real.flatten(),\n",
    "    'Selisih': (y_test_orig.flatten() - predictions_real.flatten()),\n",
    "    'Error (%)': err_pct\n",
    "})\n",
    "excel_path = os.path.join(region_out_dir, f\"{region_name}_Prediksi_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "out_df.to_excel(excel_path, index=False)\n",
    "print(f\"   ✓ Prediksi disimpan: {excel_path}\")\n",
    "\n",
    "# Ringkasan singkat\n",
    "summary = pd.DataFrame([{\n",
    "    'Region': region_name,\n",
    "    'Window Size': int(FIXED_WINDOW_SIZE),\n",
    "    'Epoch': int(FIXED_EPOCH),\n",
    "    'Batch Size': int(FIXED_BATCH_SIZE),\n",
    "    'Dropout': float(DROPOUT_RATE),\n",
    "    'Best Epoch (val)': int(best_epoch),\n",
    "    'Best Val Loss': float(best_val),\n",
    "    'Last Loss': float(last_loss),\n",
    "    'Last Val Loss': float(last_val_loss) if last_val_loss is not None else None,\n",
    "    'MAPE (%)': float(mape)\n",
    "}])\n",
    "summary_path = os.path.join(region_out_dir, f\"{region_name}_Summary_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "summary.to_excel(summary_path, index=False)\n",
    "print(f\"   ✓ Ringkasan disimpan: {summary_path}\")\n",
    "\n",
    "print(\"\\nSelesai untuk file ini.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cea9b37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data: E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Probolinggo.xlsx\n",
      "✓ Jumlah baris asli (raw): 1043\n",
      "✓ Sampel window: 1036 (window=7)\n",
      "✓ Data ternormalisasi (0-1).\n",
      "[Info] Total: 1036 | Train: 828 | Val: 83 | Test: 208\n",
      "   -> Selesai epoch : 114\n",
      "   -> Best epoch    : 114 (val_loss=0.000451)\n",
      "   -> Last loss     : 0.001199 | Last val_loss : 0.000451\n",
      "   -> MAPE          : 3.4859%\n",
      "   ✓ Model disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Probolinggo_w7_e114_b64\\Probolinggo_model_W7_E114_B64_DO0.2.h5\n",
      "   ✓ Scaler disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Probolinggo_w7_e114_b64\\Probolinggo_scaler_W7_E114_B64_DO0.2.pkl\n",
      "   ✓ Metadata disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Probolinggo_w7_e114_b64\\Probolinggo_metadata.json\n",
      "   ✓ Plot disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Probolinggo_w7_e114_b64\\Probolinggo_Plot.png\n",
      "   ✓ Prediksi disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Probolinggo_w7_e114_b64\\Probolinggo_Prediksi_W7_E114_B64.xlsx\n",
      "   ✓ Ringkasan disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Probolinggo_w7_e114_b64\\Probolinggo_Summary_W7_E114_B64.xlsx\n",
      "\n",
      "Selesai untuk file ini.\n"
     ]
    }
   ],
   "source": [
    "#PROBOLINGGO\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# ============ SEEDS ============\n",
    "def reset_seeds():\n",
    "    np.random.seed(42)\n",
    "    python_random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "reset_seeds()\n",
    "\n",
    "# ============ KONFIG TETAP (HASIL TERBAIK) ============\n",
    "FIXED_WINDOW_SIZE = 7\n",
    "FIXED_EPOCH = 114\n",
    "FIXED_BATCH_SIZE = 64\n",
    "VAL_RATIO = 0.1\n",
    "DROPOUT_RATE = 0.2\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# ============ PATH FILE (GANTI PER WILAYAH) ============\n",
    "path_file_input = r\"E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Probolinggo.xlsx\"\n",
    "output_root = r\"E:\\SKRIPSI 2025\\dataset\\FINAL\"\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "# ============ UTIL ============\n",
    "def create_sliding_window(dataset, window_size):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - window_size):\n",
    "        X.append(dataset[i:(i + window_size), 0])\n",
    "        Y.append(dataset[i + window_size, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def build_model_lstm(input_shape):\n",
    "    tf.random.set_seed(42)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                  loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# ============ LOAD DATA (SATU EXCEL) ============\n",
    "if not os.path.exists(path_file_input):\n",
    "    raise FileNotFoundError(f\"File tidak ditemukan: {path_file_input}\")\n",
    "\n",
    "df = pd.read_excel(path_file_input)\n",
    "if 'Harga (Rp)' not in df.columns:\n",
    "    raise KeyError(f\"Kolom 'Harga (Rp)' tidak ditemukan di file {path_file_input}\")\n",
    "\n",
    "raw_data = df['Harga (Rp)'].values.reshape(-1, 1)\n",
    "print(f\"✓ Data: {path_file_input}\")\n",
    "print(f\"✓ Jumlah baris asli (raw): {len(raw_data)}\")\n",
    "\n",
    "region_name = os.path.basename(path_file_input).replace(\"Data_Clean_\", \"\").replace(\".xlsx\", \"\")\n",
    "\n",
    "# ============ WINDOW DI SKALA ASLI ============\n",
    "X_full_raw, Y_full_raw = create_sliding_window(raw_data, FIXED_WINDOW_SIZE)\n",
    "print(f\"✓ Sampel window: {len(X_full_raw)} (window={FIXED_WINDOW_SIZE})\")\n",
    "train_size = int(len(X_full_raw) * 0.8)\n",
    "y_test_orig = Y_full_raw[train_size:]  # uji di skala asli\n",
    "\n",
    "# ============ SCALER FIT HANYA TRAIN (ANTI-LEAKAGE) ============\n",
    "raw_train_segment = raw_data[:train_size + FIXED_WINDOW_SIZE]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(raw_train_segment)\n",
    "scaled_data = scaler.transform(raw_data)\n",
    "print(\"✓ Data ternormalisasi (0-1).\")\n",
    "\n",
    "# ============ WINDOWING PADA DATA SCALED ============\n",
    "X_full_scaled, Y_full_scaled = create_sliding_window(scaled_data, FIXED_WINDOW_SIZE)\n",
    "X_full_scaled = X_full_scaled.reshape(X_full_scaled.shape[0], X_full_scaled.shape[1], 1)\n",
    "\n",
    "X_train_all, X_test = X_full_scaled[:train_size], X_full_scaled[train_size:]\n",
    "y_train_all = Y_full_scaled[:train_size]\n",
    "\n",
    "# Validasi tail dari TRAIN\n",
    "val_cut = int(len(X_train_all) * (1 - VAL_RATIO))\n",
    "X_train, X_val = X_train_all[:val_cut], X_train_all[val_cut:]\n",
    "y_train, y_val = y_train_all[:val_cut], y_train_all[val_cut:]\n",
    "\n",
    "print(f\"[Info] Total: {len(X_full_scaled)} | Train: {len(X_train_all)} | Val: {len(X_val)} | Test: {len(X_test)}\")\n",
    "\n",
    "# ============ TRAINING DENGAN KONFIG TETAP ============\n",
    "reset_seeds()\n",
    "model = build_model_lstm((X_train.shape[1], 1))\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=FIXED_EPOCH,\n",
    "    batch_size=FIXED_BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=0,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history.get('val_loss', None)\n",
    "last_loss = float(train_loss[-1])\n",
    "last_val_loss = float(val_loss[-1]) if val_loss is not None else None\n",
    "best_epoch = int(np.argmin(val_loss) + 1) if val_loss is not None else int(np.argmin(train_loss) + 1)\n",
    "best_val = float(np.min(val_loss)) if val_loss is not None else float(np.min(train_loss))\n",
    "\n",
    "print(f\"   -> Selesai epoch : {FIXED_EPOCH}\")\n",
    "print(f\"   -> Best epoch    : {best_epoch} (val_loss={best_val:.6f})\")\n",
    "print(f\"   -> Last loss     : {last_loss:.6f}\" + (f\" | Last val_loss : {last_val_loss:.6f}\" if last_val_loss is not None else \"\"))\n",
    "\n",
    "# ============ EVALUASI DI TEST (DENORMALIZED) ============\n",
    "predictions_scaled = model.predict(X_test, verbose=0)\n",
    "predictions_real = scaler.inverse_transform(predictions_scaled)\n",
    "mape = mean_absolute_percentage_error(y_test_orig.ravel(), predictions_real.ravel()) * 100\n",
    "print(f\"   -> MAPE          : {mape:.4f}%\")\n",
    "\n",
    "# ============ OUTPUT ============\n",
    "region_out_dir = os.path.join(output_root, f\"{region_name}_w{FIXED_WINDOW_SIZE}_e{FIXED_EPOCH}_b{FIXED_BATCH_SIZE}\")\n",
    "os.makedirs(region_out_dir, exist_ok=True)\n",
    "\n",
    "# Simpan MODEL (.h5) dan SCALER (.pkl) + metadata\n",
    "model_path = os.path.join(region_out_dir, f\"{region_name}_model_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}_DO{DROPOUT_RATE}.h5\")\n",
    "scaler_path = os.path.join(region_out_dir, f\"{region_name}_scaler_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}_DO{DROPOUT_RATE}.pkl\")\n",
    "meta_path = os.path.join(region_out_dir, f\"{region_name}_metadata.json\")\n",
    "\n",
    "# Simpan model\n",
    "model.save(model_path)\n",
    "print(f\"   ✓ Model disimpan: {model_path}\")\n",
    "\n",
    "# Simpan scaler\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f\"   ✓ Scaler disimpan: {scaler_path}\")\n",
    "\n",
    "# Simpan metadata konfigurasi dan metrik\n",
    "metadata = {\n",
    "    \"region\": region_name,\n",
    "    \"window_size\": int(FIXED_WINDOW_SIZE),\n",
    "    \"epoch\": int(FIXED_EPOCH),\n",
    "    \"batch_size\": int(FIXED_BATCH_SIZE),\n",
    "    \"dropout_rate\": float(DROPOUT_RATE),\n",
    "    \"learning_rate\": float(LEARNING_RATE),\n",
    "    \"val_ratio\": float(VAL_RATIO),\n",
    "    \"train_samples\": int(len(X_train_all)),\n",
    "    \"val_samples\": int(len(X_val)),\n",
    "    \"test_samples\": int(len(X_test)),\n",
    "    \"best_epoch_val\": int(best_epoch),\n",
    "    \"best_val_loss\": float(best_val),\n",
    "    \"last_loss\": float(last_loss),\n",
    "    \"last_val_loss\": float(last_val_loss) if last_val_loss is not None else None,\n",
    "    \"mape_test_percent\": float(mape)\n",
    "}\n",
    "with open(meta_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "print(f\"   ✓ Metadata disimpan: {meta_path}\")\n",
    "\n",
    "# Plot Actual vs Predicted\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(y_test_orig, label='Actual (Real Data)')\n",
    "plt.plot(predictions_real, label='Predicted (Denormalized)')\n",
    "plt.title(f'{region_name} | W{FIXED_WINDOW_SIZE} E{FIXED_EPOCH} B{FIXED_BATCH_SIZE} DO{DROPOUT_RATE}')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Harga')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plot_path = os.path.join(region_out_dir, f\"{region_name}_Plot.png\")\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"   ✓ Plot disimpan: {plot_path}\")\n",
    "\n",
    "# Excel per-baris\n",
    "y_test_safe = np.where(y_test_orig.flatten() == 0, np.finfo(float).eps, y_test_orig.flatten())\n",
    "err_pct = np.abs((y_test_orig.flatten() - predictions_real.flatten()) / y_test_safe) * 100\n",
    "out_df = pd.DataFrame({\n",
    "    'Actual (Real)': y_test_orig.flatten(),\n",
    "    'Predicted (Real)': predictions_real.flatten(),\n",
    "    'Selisih': (y_test_orig.flatten() - predictions_real.flatten()),\n",
    "    'Error (%)': err_pct\n",
    "})\n",
    "excel_path = os.path.join(region_out_dir, f\"{region_name}_Prediksi_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "out_df.to_excel(excel_path, index=False)\n",
    "print(f\"   ✓ Prediksi disimpan: {excel_path}\")\n",
    "\n",
    "# Ringkasan singkat\n",
    "summary = pd.DataFrame([{\n",
    "    'Region': region_name,\n",
    "    'Window Size': int(FIXED_WINDOW_SIZE),\n",
    "    'Epoch': int(FIXED_EPOCH),\n",
    "    'Batch Size': int(FIXED_BATCH_SIZE),\n",
    "    'Dropout': float(DROPOUT_RATE),\n",
    "    'Best Epoch (val)': int(best_epoch),\n",
    "    'Best Val Loss': float(best_val),\n",
    "    'Last Loss': float(last_loss),\n",
    "    'Last Val Loss': float(last_val_loss) if last_val_loss is not None else None,\n",
    "    'MAPE (%)': float(mape)\n",
    "}])\n",
    "summary_path = os.path.join(region_out_dir, f\"{region_name}_Summary_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "summary.to_excel(summary_path, index=False)\n",
    "print(f\"   ✓ Ringkasan disimpan: {summary_path}\")\n",
    "\n",
    "print(\"\\nSelesai untuk file ini.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62a6766a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data: E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Sumenep.xlsx\n",
      "✓ Jumlah baris asli (raw): 1043\n",
      "✓ Sampel window: 1036 (window=7)\n",
      "✓ Data ternormalisasi (0-1).\n",
      "[Info] Total: 1036 | Train: 828 | Val: 83 | Test: 208\n",
      "   -> Selesai epoch : 114\n",
      "   -> Best epoch    : 114 (val_loss=0.000221)\n",
      "   -> Last loss     : 0.000738 | Last val_loss : 0.000221\n",
      "   -> MAPE          : 2.0828%\n",
      "   ✓ Model disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Sumenep_w7_e114_b64\\Sumenep_model_W7_E114_B64_DO0.2.h5\n",
      "   ✓ Scaler disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Sumenep_w7_e114_b64\\Sumenep_scaler_W7_E114_B64_DO0.2.pkl\n",
      "   ✓ Metadata disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Sumenep_w7_e114_b64\\Sumenep_metadata.json\n",
      "   ✓ Plot disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Sumenep_w7_e114_b64\\Sumenep_Plot.png\n",
      "   ✓ Prediksi disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Sumenep_w7_e114_b64\\Sumenep_Prediksi_W7_E114_B64.xlsx\n",
      "   ✓ Ringkasan disimpan: E:\\SKRIPSI 2025\\dataset\\FINAL\\Sumenep_w7_e114_b64\\Sumenep_Summary_W7_E114_B64.xlsx\n",
      "\n",
      "Selesai untuk file ini.\n"
     ]
    }
   ],
   "source": [
    "#SUMENEP\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# ============ SEEDS ============\n",
    "def reset_seeds():\n",
    "    np.random.seed(42)\n",
    "    python_random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "reset_seeds()\n",
    "\n",
    "# ============ KONFIG TETAP (HASIL TERBAIK) ============\n",
    "FIXED_WINDOW_SIZE = 7\n",
    "FIXED_EPOCH = 114\n",
    "FIXED_BATCH_SIZE = 64\n",
    "VAL_RATIO = 0.1\n",
    "DROPOUT_RATE = 0.2\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# ============ PATH FILE (GANTI PER WILAYAH) ============\n",
    "path_file_input = r\"E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Sumenep.xlsx\"\n",
    "output_root = r\"E:\\SKRIPSI 2025\\dataset\\FINAL\"\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "# ============ UTIL ============\n",
    "def create_sliding_window(dataset, window_size):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - window_size):\n",
    "        X.append(dataset[i:(i + window_size), 0])\n",
    "        Y.append(dataset[i + window_size, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def build_model_lstm(input_shape):\n",
    "    tf.random.set_seed(42)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                  loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# ============ LOAD DATA (SATU EXCEL) ============\n",
    "if not os.path.exists(path_file_input):\n",
    "    raise FileNotFoundError(f\"File tidak ditemukan: {path_file_input}\")\n",
    "\n",
    "df = pd.read_excel(path_file_input)\n",
    "if 'Harga (Rp)' not in df.columns:\n",
    "    raise KeyError(f\"Kolom 'Harga (Rp)' tidak ditemukan di file {path_file_input}\")\n",
    "\n",
    "raw_data = df['Harga (Rp)'].values.reshape(-1, 1)\n",
    "print(f\"✓ Data: {path_file_input}\")\n",
    "print(f\"✓ Jumlah baris asli (raw): {len(raw_data)}\")\n",
    "\n",
    "region_name = os.path.basename(path_file_input).replace(\"Data_Clean_\", \"\").replace(\".xlsx\", \"\")\n",
    "\n",
    "# ============ WINDOW DI SKALA ASLI ============\n",
    "X_full_raw, Y_full_raw = create_sliding_window(raw_data, FIXED_WINDOW_SIZE)\n",
    "print(f\"✓ Sampel window: {len(X_full_raw)} (window={FIXED_WINDOW_SIZE})\")\n",
    "train_size = int(len(X_full_raw) * 0.8)\n",
    "y_test_orig = Y_full_raw[train_size:]  # uji di skala asli\n",
    "\n",
    "# ============ SCALER FIT HANYA TRAIN (ANTI-LEAKAGE) ============\n",
    "raw_train_segment = raw_data[:train_size + FIXED_WINDOW_SIZE]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(raw_train_segment)\n",
    "scaled_data = scaler.transform(raw_data)\n",
    "print(\"✓ Data ternormalisasi (0-1).\")\n",
    "\n",
    "# ============ WINDOWING PADA DATA SCALED ============\n",
    "X_full_scaled, Y_full_scaled = create_sliding_window(scaled_data, FIXED_WINDOW_SIZE)\n",
    "X_full_scaled = X_full_scaled.reshape(X_full_scaled.shape[0], X_full_scaled.shape[1], 1)\n",
    "\n",
    "X_train_all, X_test = X_full_scaled[:train_size], X_full_scaled[train_size:]\n",
    "y_train_all = Y_full_scaled[:train_size]\n",
    "\n",
    "# Validasi tail dari TRAIN\n",
    "val_cut = int(len(X_train_all) * (1 - VAL_RATIO))\n",
    "X_train, X_val = X_train_all[:val_cut], X_train_all[val_cut:]\n",
    "y_train, y_val = y_train_all[:val_cut], y_train_all[val_cut:]\n",
    "\n",
    "print(f\"[Info] Total: {len(X_full_scaled)} | Train: {len(X_train_all)} | Val: {len(X_val)} | Test: {len(X_test)}\")\n",
    "\n",
    "# ============ TRAINING DENGAN KONFIG TETAP ============\n",
    "reset_seeds()\n",
    "model = build_model_lstm((X_train.shape[1], 1))\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=FIXED_EPOCH,\n",
    "    batch_size=FIXED_BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=0,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history.get('val_loss', None)\n",
    "last_loss = float(train_loss[-1])\n",
    "last_val_loss = float(val_loss[-1]) if val_loss is not None else None\n",
    "best_epoch = int(np.argmin(val_loss) + 1) if val_loss is not None else int(np.argmin(train_loss) + 1)\n",
    "best_val = float(np.min(val_loss)) if val_loss is not None else float(np.min(train_loss))\n",
    "\n",
    "print(f\"   -> Selesai epoch : {FIXED_EPOCH}\")\n",
    "print(f\"   -> Best epoch    : {best_epoch} (val_loss={best_val:.6f})\")\n",
    "print(f\"   -> Last loss     : {last_loss:.6f}\" + (f\" | Last val_loss : {last_val_loss:.6f}\" if last_val_loss is not None else \"\"))\n",
    "\n",
    "# ============ EVALUASI DI TEST (DENORMALIZED) ============\n",
    "predictions_scaled = model.predict(X_test, verbose=0)\n",
    "predictions_real = scaler.inverse_transform(predictions_scaled)\n",
    "mape = mean_absolute_percentage_error(y_test_orig.ravel(), predictions_real.ravel()) * 100\n",
    "print(f\"   -> MAPE          : {mape:.4f}%\")\n",
    "\n",
    "# ============ OUTPUT ============\n",
    "region_out_dir = os.path.join(output_root, f\"{region_name}_w{FIXED_WINDOW_SIZE}_e{FIXED_EPOCH}_b{FIXED_BATCH_SIZE}\")\n",
    "os.makedirs(region_out_dir, exist_ok=True)\n",
    "\n",
    "# Simpan MODEL (.h5) dan SCALER (.pkl) + metadata\n",
    "model_path = os.path.join(region_out_dir, f\"{region_name}_model_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}_DO{DROPOUT_RATE}.h5\")\n",
    "scaler_path = os.path.join(region_out_dir, f\"{region_name}_scaler_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}_DO{DROPOUT_RATE}.pkl\")\n",
    "meta_path = os.path.join(region_out_dir, f\"{region_name}_metadata.json\")\n",
    "\n",
    "# Simpan model\n",
    "model.save(model_path)\n",
    "print(f\"   ✓ Model disimpan: {model_path}\")\n",
    "\n",
    "# Simpan scaler\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f\"   ✓ Scaler disimpan: {scaler_path}\")\n",
    "\n",
    "# Simpan metadata konfigurasi dan metrik\n",
    "metadata = {\n",
    "    \"region\": region_name,\n",
    "    \"window_size\": int(FIXED_WINDOW_SIZE),\n",
    "    \"epoch\": int(FIXED_EPOCH),\n",
    "    \"batch_size\": int(FIXED_BATCH_SIZE),\n",
    "    \"dropout_rate\": float(DROPOUT_RATE),\n",
    "    \"learning_rate\": float(LEARNING_RATE),\n",
    "    \"val_ratio\": float(VAL_RATIO),\n",
    "    \"train_samples\": int(len(X_train_all)),\n",
    "    \"val_samples\": int(len(X_val)),\n",
    "    \"test_samples\": int(len(X_test)),\n",
    "    \"best_epoch_val\": int(best_epoch),\n",
    "    \"best_val_loss\": float(best_val),\n",
    "    \"last_loss\": float(last_loss),\n",
    "    \"last_val_loss\": float(last_val_loss) if last_val_loss is not None else None,\n",
    "    \"mape_test_percent\": float(mape)\n",
    "}\n",
    "with open(meta_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "print(f\"   ✓ Metadata disimpan: {meta_path}\")\n",
    "\n",
    "# Plot Actual vs Predicted\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(y_test_orig, label='Actual (Real Data)')\n",
    "plt.plot(predictions_real, label='Predicted (Denormalized)')\n",
    "plt.title(f'{region_name} | W{FIXED_WINDOW_SIZE} E{FIXED_EPOCH} B{FIXED_BATCH_SIZE} DO{DROPOUT_RATE}')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Harga')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plot_path = os.path.join(region_out_dir, f\"{region_name}_Plot.png\")\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"   ✓ Plot disimpan: {plot_path}\")\n",
    "\n",
    "# Excel per-baris\n",
    "y_test_safe = np.where(y_test_orig.flatten() == 0, np.finfo(float).eps, y_test_orig.flatten())\n",
    "err_pct = np.abs((y_test_orig.flatten() - predictions_real.flatten()) / y_test_safe) * 100\n",
    "out_df = pd.DataFrame({\n",
    "    'Actual (Real)': y_test_orig.flatten(),\n",
    "    'Predicted (Real)': predictions_real.flatten(),\n",
    "    'Selisih': (y_test_orig.flatten() - predictions_real.flatten()),\n",
    "    'Error (%)': err_pct\n",
    "})\n",
    "excel_path = os.path.join(region_out_dir, f\"{region_name}_Prediksi_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "out_df.to_excel(excel_path, index=False)\n",
    "print(f\"   ✓ Prediksi disimpan: {excel_path}\")\n",
    "\n",
    "# Ringkasan singkat\n",
    "summary = pd.DataFrame([{\n",
    "    'Region': region_name,\n",
    "    'Window Size': int(FIXED_WINDOW_SIZE),\n",
    "    'Epoch': int(FIXED_EPOCH),\n",
    "    'Batch Size': int(FIXED_BATCH_SIZE),\n",
    "    'Dropout': float(DROPOUT_RATE),\n",
    "    'Best Epoch (val)': int(best_epoch),\n",
    "    'Best Val Loss': float(best_val),\n",
    "    'Last Loss': float(last_loss),\n",
    "    'Last Val Loss': float(last_val_loss) if last_val_loss is not None else None,\n",
    "    'MAPE (%)': float(mape)\n",
    "}])\n",
    "summary_path = os.path.join(region_out_dir, f\"{region_name}_Summary_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "summary.to_excel(summary_path, index=False)\n",
    "print(f\"   ✓ Ringkasan disimpan: {summary_path}\")\n",
    "\n",
    "print(\"\\nSelesai untuk file ini.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5ef970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb46609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
