{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d63140e2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "126be11c",
   "metadata": {},
   "source": [
    "MULAI PADA UJI COBA SESUAI BAB 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c43dcc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data berhasil dimuat.\n",
      "✓ Jumlah baris asli (raw): 1043\n",
      "\n",
      "==================================================\n",
      "MULAI SKENARIO A (WINDOW BESAR)\n",
      "==================================================\n",
      "\n",
      "[Proses] Training Window Size: 30 ...\n",
      "   -> Window samples: 1013 (window=30)\n",
      "   -> Selesai epoch : 16\n",
      "   -> Best epoch    : 16 (val_loss=0.000621)\n",
      "   -> Last loss      : 0.001971 | Last val_loss : 0.000621\n",
      "   -> MAPE Window 30: 4.5381%\n",
      "   ✓ Grafik disimpan: E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\\Grafik_Window_30.png\n",
      "   ✓ Hasil Excel disimpan: E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\\Prediksi_Window_30.xlsx\n",
      "\n",
      "[Proses] Training Window Size: 60 ...\n",
      "   -> Window samples: 983 (window=60)\n",
      "   -> Selesai epoch : 16\n",
      "   -> Best epoch    : 16 (val_loss=0.000693)\n",
      "   -> Last loss      : 0.001436 | Last val_loss : 0.000693\n",
      "   -> MAPE Window 60: 4.3833%\n",
      "   ✓ Grafik disimpan: E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\\Grafik_Window_60.png\n",
      "   ✓ Hasil Excel disimpan: E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\\Prediksi_Window_60.xlsx\n",
      "\n",
      "[Proses] Training Window Size: 90 ...\n",
      "   -> Window samples: 953 (window=90)\n",
      "   -> Selesai epoch : 16\n",
      "   -> Best epoch    : 14 (val_loss=0.001218)\n",
      "   -> Last loss      : 0.001766 | Last val_loss : 0.001372\n",
      "   -> MAPE Window 90: 4.1190%\n",
      "   ✓ Grafik disimpan: E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\\Grafik_Window_90.png\n",
      "   ✓ Hasil Excel disimpan: E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\\Prediksi_Window_90.xlsx\n",
      "\n",
      "==================================================\n",
      "   Window Size  MAPE (%)  Best Epoch  Best Loss  Last Loss  Last Val Loss\n",
      "0           30  4.538132          16   0.000621   0.001971       0.000621\n",
      "1           60  4.383324          16   0.000693   0.001436       0.000693\n",
      "2           90  4.118962          14   0.001218   0.001766       0.001372\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "#MENCARI KONFIGURASI WINDOW SIZE TERBAIK SESUAI BAB 3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random as python_random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "def reset_seeds():\n",
    "    np.random.seed(42)\n",
    "    python_random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "reset_seeds()\n",
    "\n",
    "path_file_input = r\"E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Surabaya.xlsx\"\n",
    "path_output_folder = r\"E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\"\n",
    "os.makedirs(path_output_folder, exist_ok=True)\n",
    "\n",
    "if os.path.exists(path_file_input):\n",
    "    df = pd.read_excel(path_file_input)\n",
    " \n",
    "    nama_kolom_tanggal = 'Tanggal' \n",
    "    if nama_kolom_tanggal not in df.columns:\n",
    "         \n",
    "        if 'Date' in df.columns:\n",
    "            nama_kolom_tanggal = 'Date'\n",
    "        else:\n",
    "            raise KeyError(\"Kolom Tanggal tidak ditemukan!\")\n",
    "            \n",
    "    df[nama_kolom_tanggal] = pd.to_datetime(df[nama_kolom_tanggal])\n",
    "    print(\"✓ Data berhasil dimuat.\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"File tidak ditemukan!\")\n",
    "\n",
    "raw_data = df['Harga (Rp)'].values.reshape(-1, 1)\n",
    "print(f\"✓ Jumlah baris asli (raw): {len(raw_data)}\")\n",
    "\n",
    "def create_sliding_window(dataset, window_size):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - window_size):\n",
    "        X.append(dataset[i:(i + window_size), 0])\n",
    "        Y.append(dataset[i + window_size, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def build_model_lstm(input_shape):\n",
    "    tf.random.set_seed(42)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.02))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(0.02))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "scenario_windows = [30, 60, 90] \n",
    "FIXED_EPOCH = 16                 \n",
    "FIXED_BATCH_SIZE = 30\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MULAI SKENARIO A (WINDOW BESAR)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for win_size in scenario_windows:\n",
    "    print(f\"\\n[Proses] Training Window Size: {win_size} ...\")\n",
    "    reset_seeds()\n",
    "\n",
    "    X_full_raw, Y_full_raw = create_sliding_window(raw_data, win_size)\n",
    "    print(f\"   -> Window samples: {len(X_full_raw)} (window={win_size})\") \n",
    "    \n",
    "    train_size = int(len(X_full_raw) * 0.8)\n",
    "    y_test_orig = Y_full_raw[train_size:] \n",
    "    \n",
    "    \n",
    "\n",
    "    all_dates_Y = df[nama_kolom_tanggal].values[win_size:] \n",
    "    test_dates = all_dates_Y[train_size:] \n",
    "    \n",
    "\n",
    "    raw_train_segment = raw_data[:train_size + win_size]\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler.fit(raw_train_segment)\n",
    "    scaled_data = scaler.transform(raw_data)\n",
    "    \n",
    "    X_full_scaled, Y_full_scaled = create_sliding_window(scaled_data, win_size)\n",
    "    X_full_scaled = X_full_scaled.reshape(X_full_scaled.shape[0], X_full_scaled.shape[1], 1)\n",
    "    X_train, X_test = X_full_scaled[:train_size], X_full_scaled[train_size:]\n",
    "    y_train = Y_full_scaled[:train_size]\n",
    "\n",
    "    model = build_model_lstm((X_train.shape[1], 1))\n",
    "\n",
    "  \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=FIXED_EPOCH,\n",
    "        batch_size=FIXED_BATCH_SIZE,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0,\n",
    "        shuffle=False,\n",
    "        validation_split=0.1  \n",
    "    )\n",
    "\n",
    "    finished_epoch = len(history.history['loss'])\n",
    "    best_epoch = np.argmin(history.history['val_loss']) + 1 if 'val_loss' in history.history else np.argmin(history.history['loss']) + 1\n",
    "    best_loss = np.min(history.history['val_loss']) if 'val_loss' in history.history else np.min(history.history['loss'])\n",
    "    last_loss = float(history.history['loss'][-1]) \n",
    "    last_val_loss = float(history.history['val_loss'][-1]) if 'val_loss' in history.history else None  \n",
    "\n",
    "    print(f\"   -> Selesai epoch : {finished_epoch}\")\n",
    "    print(f\"   -> Best epoch    : {best_epoch} (val_loss={best_loss:.6f})\")\n",
    "    if last_val_loss is not None:\n",
    "        print(f\"   -> Last loss      : {last_loss:.6f} | Last val_loss : {last_val_loss:.6f}\")\n",
    "    else:\n",
    "        print(f\"   -> Last loss      : {last_loss:.6f}\")\n",
    "\n",
    "    \n",
    "    predictions_scaled = model.predict(X_test, verbose=0) \n",
    "    predictions_real = scaler.inverse_transform(predictions_scaled)\n",
    "\n",
    "    mape = mean_absolute_percentage_error(y_test_orig, predictions_real) * 100\n",
    "    print(f\"   -> MAPE Window {win_size}: {mape:.4f}%\")\n",
    "\n",
    "    results.append({\n",
    "        'Window Size': win_size,\n",
    "        'MAPE (%)': float(mape),\n",
    "        'Best Epoch': int(best_epoch),\n",
    "        'Best Loss': float(best_loss),\n",
    "        'Last Loss': float(last_loss),\n",
    "        'Last Val Loss': float(last_val_loss) if last_val_loss is not None else None\n",
    "    })\n",
    "\n",
    " \n",
    "    plt.figure(figsize=(12, 6)) \n",
    "    plt.plot(test_dates, y_test_orig, label='Actual (Real Data)')\n",
    "    plt.plot(test_dates, predictions_real, label='Predicted (Denormalized)')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted (Window {win_size})')\n",
    "    plt.xlabel('Tanggal dan Tahun')\n",
    "    plt.ylabel('Harga (Rp)')\n",
    "    \n",
    "    # Format Tanggal\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Simpan Gambar otomatis biar bisa dilihat nanti\n",
    "    img_path = os.path.join(path_output_folder, f\"Grafik_Window_{win_size}.png\")\n",
    "    plt.savefig(img_path, bbox_inches='tight')\n",
    "    plt.close() \n",
    "    print(f\"   ✓ Grafik disimpan: {img_path}\")\n",
    "\n",
    "\n",
    "    y_test_safe = np.where(y_test_orig.flatten() == 0, np.finfo(float).eps, y_test_orig.flatten())\n",
    "    err_pct = np.abs((y_test_orig.flatten() - predictions_real.flatten()) / y_test_safe) * 100\n",
    "\n",
    "    out_df = pd.DataFrame({\n",
    "        'Tanggal': test_dates, \n",
    "        'Actual (Real)': y_test_orig.flatten(),\n",
    "        'Predicted (Real)': predictions_real.flatten(),\n",
    "        'Selisih': (y_test_orig.flatten() - predictions_real.flatten()),\n",
    "        'Error (%)': err_pct\n",
    "    })\n",
    "\n",
    "    out_path = os.path.join(path_output_folder, f\"Prediksi_Window_{win_size}.xlsx\")\n",
    "    out_df.to_excel(out_path, index=False)\n",
    "    print(f\"   ✓ Hasil Excel disimpan: {out_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_excel(os.path.join(path_output_folder, \"REKAP_MAPE_ALL_WINDOWS.xlsx\"), index=False)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2585f176",
   "metadata": {},
   "source": [
    "NORMALISASI DATA DAN MELIHAT DATA HASIL NORMALISASI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37934ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data berhasil dimuat.\n",
      "\n",
      "--- Sampel Hasil Normalisasi (20 Baris Pertama) ---\n",
      "      Tanggal  Harga Asli (Rp)  Harga Normalisasi\n",
      "0  2021-01-01            28250           0.150000\n",
      "1  2021-01-04            28250           0.150000\n",
      "2  2021-01-05            28250           0.150000\n",
      "3  2021-01-06            28250           0.150000\n",
      "4  2021-01-07            28250           0.150000\n",
      "5  2021-01-08            28250           0.150000\n",
      "6  2021-01-11            27250           0.131818\n",
      "7  2021-01-12            27250           0.131818\n",
      "8  2021-01-13            27250           0.131818\n",
      "9  2021-01-14            27750           0.140909\n",
      "10 2021-01-15            27250           0.131818\n",
      "11 2021-01-18            27750           0.140909\n",
      "12 2021-01-19            27750           0.140909\n",
      "13 2021-01-20            27250           0.131818\n",
      "14 2021-01-21            26250           0.113636\n",
      "15 2021-01-22            26250           0.113636\n",
      "16 2021-01-25            26250           0.113636\n",
      "17 2021-01-26            25750           0.104545\n",
      "18 2021-01-27            25750           0.104545\n",
      "19 2021-01-28            25750           0.104545\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "\n",
    "\n",
    "path_file_input = r\"E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Surabaya.xlsx\"\n",
    "\n",
    "# Cek apakah file ada\n",
    "if os.path.exists(path_file_input):\n",
    "    df = pd.read_excel(path_file_input)\n",
    "    print(\"✓ Data berhasil dimuat.\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"File tidak ditemukan di: {path_file_input}\")\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "\n",
    "train_size = int(len(df) * 0.8)\n",
    "raw_train = df['Harga (Rp)'].values[:train_size].reshape(-1, 1)\n",
    "\n",
    "scaler.fit(raw_train)  \n",
    "\n",
    "all_data_raw = df['Harga (Rp)'].values.reshape(-1, 1)\n",
    "scaled_data = scaler.transform(all_data_raw)\n",
    "\n",
    "# Masukkan hasil ke DataFrame\n",
    "df['Harga_Normalized'] = scaled_data\n",
    "\n",
    "\n",
    "tabel_cek = pd.DataFrame({\n",
    "    'Tanggal': df['Tanggal'].iloc[:20] if 'Tanggal' in df.columns else range(20),\n",
    "    'Harga Asli (Rp)': df['Harga (Rp)'].iloc[:20].values,\n",
    "    'Harga Normalisasi': df['Harga_Normalized'].iloc[:20].values\n",
    "})\n",
    "\n",
    "print(\"\\n--- Sampel Hasil Normalisasi (20 Baris Pertama) ---\")\n",
    "print(tabel_cek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "131a34b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data dan Tanggal berhasil dimuat.\n",
      "✓ Jumlah baris asli (raw): 1043\n",
      "✓ Jumlah sampel window: 953 (window=90)\n",
      "✓ Data ternormalisasi (0-1).\n",
      "\n",
      "============================================================\n",
      "MULAI FASE 2: SKENARIO B (Grid Epoch: 16, 30, 50)\n",
      "Kondisi: Dengan Normalisasi, Tanpa EarlyStopping (epoch tetap), Val=tail train\n",
      "============================================================\n",
      "\n",
      "[Training] Epoch = 16, Window = 90\n",
      "   -> Selesai epoch : 16\n",
      "   -> Best epoch    : 14 (val_loss=0.001218)\n",
      "   -> MAPE          : 4.1190%\n",
      "   ✓ Grafik disimpan: E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\\Grafik_Epoch_16_Window_90.png\n",
      "   ✓ Excel disimpan: E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\\Prediksi_Epoch_16_Window_90.xlsx\n",
      "\n",
      "[Training] Epoch = 30, Window = 90\n",
      "   -> Selesai epoch : 30\n",
      "   -> Best epoch    : 30 (val_loss=0.000986)\n",
      "   -> MAPE          : 3.7639%\n",
      "   ✓ Grafik disimpan: E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\\Grafik_Epoch_30_Window_90.png\n",
      "   ✓ Excel disimpan: E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\\Prediksi_Epoch_30_Window_90.xlsx\n",
      "\n",
      "[Training] Epoch = 50, Window = 90\n",
      "   -> Selesai epoch : 50\n",
      "   -> Best epoch    : 47 (val_loss=0.000808)\n",
      "   -> MAPE          : 3.3472%\n",
      "   ✓ Grafik disimpan: E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\\Grafik_Epoch_50_Window_90.png\n",
      "   ✓ Excel disimpan: E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\\Prediksi_Epoch_50_Window_90.xlsx\n",
      "\n",
      "============================================================\n",
      "   Jumlah Epoch  Best Epoch (val)  Best Loss (val)  Last Loss  Last Val Loss  \\\n",
      "0            16                14         0.001218   0.001766       0.001372   \n",
      "1            30                30         0.000986   0.001530       0.000986   \n",
      "2            50                47         0.000808   0.001033       0.000959   \n",
      "\n",
      "   MAPE (%)  \n",
      "0  4.118962  \n",
      "1  3.763897  \n",
      "2  3.347179  \n",
      "============================================================\n",
      "Kesimpulan: Epoch terbaik (grid) = 50 dengan MAPE 3.3472%\n"
     ]
    }
   ],
   "source": [
    "#MENCARI KONFIGURASI EPOCH TERBAIK SESUAI BAB 3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random as python_random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "\n",
    "def reset_seeds():\n",
    "    np.random.seed(42)\n",
    "    python_random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "reset_seeds()\n",
    "\n",
    "\n",
    "path_file_input = r\"E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Surabaya.xlsx\"\n",
    "path_output_folder = r\"E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\"\n",
    "os.makedirs(path_output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "if os.path.exists(path_file_input):\n",
    "    df = pd.read_excel(path_file_input)\n",
    "    \n",
    "\n",
    "    nama_kolom_tanggal = 'Tanggal' \n",
    "    if nama_kolom_tanggal not in df.columns:\n",
    "        raise KeyError(\"Kolom 'Tanggal' tidak ditemukan di Excel!\")\n",
    "            \n",
    "   \n",
    "    df[nama_kolom_tanggal] = pd.to_datetime(df[nama_kolom_tanggal])\n",
    "    print(\"✓ Data dan Tanggal berhasil dimuat.\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"File tidak ditemukan.\")\n",
    "\n",
    "raw_data = df['Harga (Rp)'].values.reshape(-1, 1)\n",
    "print(f\"✓ Jumlah baris asli (raw): {len(raw_data)}\")\n",
    "\n",
    "\n",
    "FIXED_WINDOW_SIZE = 90\n",
    "FIXED_BATCH_SIZE = 30\n",
    "scenario_epochs = [16, 30, 50]  \n",
    "VAL_RATIO = 0.1                  \n",
    "\n",
    "\n",
    "def create_sliding_window(dataset, window_size):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - window_size):\n",
    "        X.append(dataset[i:(i + window_size), 0])\n",
    "        Y.append(dataset[i + window_size, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def build_model_lstm(input_shape):\n",
    "    tf.random.set_seed(42)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.02))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(0.02))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "X_full_raw, Y_full_raw = create_sliding_window(raw_data, FIXED_WINDOW_SIZE)\n",
    "print(f\"✓ Jumlah sampel window: {len(X_full_raw)} (window={FIXED_WINDOW_SIZE})\")\n",
    "train_size = int(len(X_full_raw) * 0.8)\n",
    "y_test_orig = Y_full_raw[train_size:]  \n",
    "\n",
    "\n",
    "all_dates = df[nama_kolom_tanggal].values[FIXED_WINDOW_SIZE:]\n",
    "test_dates = all_dates[train_size:]\n",
    "\n",
    "raw_train_segment = raw_data[:train_size + FIXED_WINDOW_SIZE]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(raw_train_segment)\n",
    "\n",
    "scaled_data = scaler.transform(raw_data)\n",
    "print(\"✓ Data ternormalisasi (0-1).\")\n",
    "\n",
    "X_full_scaled, Y_full_scaled = create_sliding_window(scaled_data, FIXED_WINDOW_SIZE)\n",
    "\n",
    "X_full_scaled = X_full_scaled.reshape(X_full_scaled.shape[0], X_full_scaled.shape[1], 1)\n",
    "X_train_all, X_test = X_full_scaled[:train_size], X_full_scaled[train_size:]\n",
    "y_train_all = Y_full_scaled[:train_size]\n",
    "\n",
    "# Split validasi dari tail train\n",
    "val_cut = int(len(X_train_all) * (1 - VAL_RATIO))\n",
    "X_train, X_val = X_train_all[:val_cut], X_train_all[val_cut:]\n",
    "y_train, y_val = y_train_all[:val_cut], y_train_all[val_cut:]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MULAI FASE 2: SKENARIO B (Grid Epoch: 16, 30, 50)\")\n",
    "print(\"Kondisi: Dengan Normalisasi, Tanpa EarlyStopping (epoch tetap), Val=tail train\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "for epoch_count in scenario_epochs:\n",
    "    print(f\"\\n[Training] Epoch = {epoch_count}, Window = {FIXED_WINDOW_SIZE}\")\n",
    "    reset_seeds()\n",
    "\n",
    "    model = build_model_lstm((X_train.shape[1], 1))\n",
    "   \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epoch_count,\n",
    "        batch_size=FIXED_BATCH_SIZE,\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    \n",
    "    finished_epoch = epoch_count\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history.get('val_loss', None)\n",
    "\n",
    "    if val_loss is not None:\n",
    "        best_epoch = int(np.argmin(val_loss) + 1)\n",
    "        best_loss = float(np.min(val_loss))\n",
    "        last_loss = float(train_loss[-1])\n",
    "        last_val_loss = float(val_loss[-1])\n",
    "        print(f\"   -> Selesai epoch : {finished_epoch}\")\n",
    "        print(f\"   -> Best epoch    : {best_epoch} (val_loss={best_loss:.6f})\")\n",
    "    else:\n",
    "        \n",
    "        best_epoch = int(np.argmin(train_loss) + 1)\n",
    "        best_loss = float(np.min(train_loss))\n",
    "        last_loss = float(train_loss[-1])\n",
    "        last_val_loss = None\n",
    "        print(f\"   -> Selesai epoch : {finished_epoch}\")\n",
    "\n",
    "    \n",
    "    predictions_scaled = model.predict(X_test, verbose=0)\n",
    "    predictions_real = scaler.inverse_transform(predictions_scaled)\n",
    "\n",
    "    mape = mean_absolute_percentage_error(y_test_orig, predictions_real) * 100\n",
    "    print(f\"   -> MAPE          : {mape:.4f}%\")\n",
    "\n",
    "    results.append({\n",
    "        'Jumlah Epoch': int(epoch_count),\n",
    "        'Best Epoch (val)': int(best_epoch),\n",
    "        'Best Loss (val)': float(best_loss),\n",
    "        'Last Loss': float(last_loss),\n",
    "        'Last Val Loss': float(last_val_loss) if last_val_loss is not None else None,\n",
    "        'MAPE (%)': float(mape)\n",
    "    })\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12, 6)) \n",
    "    plt.plot(test_dates, y_test_orig, label='Actual (Real Data)')\n",
    "    plt.plot(test_dates, predictions_real, label='Predicted (Denormalized)')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted (Epoch {epoch_count}, Window {FIXED_WINDOW_SIZE})')\n",
    "    plt.xlabel('Tanggal dan Tahun')\n",
    "    plt.ylabel('Harga (Rp)')\n",
    "    \n",
    "    # Format Tanggal\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    \n",
    "    img_path = os.path.join(path_output_folder, f\"Grafik_Epoch_{epoch_count}_Window_{FIXED_WINDOW_SIZE}.png\")\n",
    "    plt.savefig(img_path, bbox_inches='tight')\n",
    "    plt.close() \n",
    "    print(f\"   ✓ Grafik disimpan: {img_path}\")\n",
    "\n",
    "\n",
    "    y_test_safe = np.where(y_test_orig.flatten() == 0, np.finfo(float).eps, y_test_orig.flatten())\n",
    "    err_pct = np.abs((y_test_orig.flatten() - predictions_real.flatten()) / y_test_safe) * 100\n",
    "\n",
    "    out_df = pd.DataFrame({\n",
    "        'Tanggal': test_dates, \n",
    "        'Actual (Real)': y_test_orig.flatten(),\n",
    "        'Predicted (Real)': predictions_real.flatten(),\n",
    "        'Selisih': (y_test_orig.flatten() - predictions_real.flatten()),\n",
    "        'Error (%)': err_pct\n",
    "    })\n",
    "    out_path = os.path.join(path_output_folder, f\"Prediksi_Epoch_{epoch_count}_Window_{FIXED_WINDOW_SIZE}.xlsx\")\n",
    "    out_df.to_excel(out_path, index=False)\n",
    "    print(f\"   ✓ Excel disimpan: {out_path}\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "best_result = results_df.loc[results_df['MAPE (%)'].idxmin()]\n",
    "best_epoch_param = int(best_result['Jumlah Epoch'])\n",
    "print(f\"Kesimpulan: Epoch terbaik (grid) = {best_epoch_param} dengan MAPE {best_result['MAPE (%)']:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13d11f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data dan Tanggal berhasil dimuat.\n",
      "✓ Jumlah baris asli (raw): 1043\n",
      "✓ Jumlah sampel window: 953 (window=90)\n",
      "✓ Data ternormalisasi (0-1).\n",
      "\n",
      "[Info] Dataset Window Size: 90\n",
      "----------------------------------------\n",
      "Total Window Samples: 953 | Latih: 762 | Uji: 191\n",
      "----------------------------------------\n",
      "\n",
      "============================================================\n",
      "MULAI FASE 2: SKENARIO C (Mencari Batch Size Terbaik)\n",
      "Konfigurasi: Window 90 | Epoch 50\n",
      "============================================================\n",
      "\n",
      "[Proses] Training dengan Batch Size: 16 ...\n",
      "   -> Selesai epoch : 50\n",
      "   -> Best epoch    : 46 (val_loss=0.000737)\n",
      "   -> Last loss     : 0.001218 | Last val_loss : 0.001011\n",
      "6/6 [==============================] - 8s 202ms/step\n",
      "   -> Selesai. Hasil MAPE: 5.5420%\n",
      "   ✓ Grafik disimpan: E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\\Grafik_Batch_16_Window_90.png\n",
      "   ✓ Excel disimpan: E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\\Prediksi_Batch_16_Window_90_Epoch_50.xlsx\n",
      "\n",
      "[Proses] Training dengan Batch Size: 30 ...\n",
      "   -> Selesai epoch : 50\n",
      "   -> Best epoch    : 47 (val_loss=0.000808)\n",
      "   -> Last loss     : 0.001033 | Last val_loss : 0.000959\n",
      "6/6 [==============================] - 2s 77ms/step\n",
      "   -> Selesai. Hasil MAPE: 3.3472%\n",
      "   ✓ Grafik disimpan: E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\\Grafik_Batch_30_Window_90.png\n",
      "   ✓ Excel disimpan: E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\\Prediksi_Batch_30_Window_90_Epoch_50.xlsx\n",
      "\n",
      "[Proses] Training dengan Batch Size: 64 ...\n",
      "   -> Selesai epoch : 50\n",
      "   -> Best epoch    : 49 (val_loss=0.000944)\n",
      "   -> Last loss     : 0.000899 | Last val_loss : 0.000987\n",
      "6/6 [==============================] - 2s 85ms/step\n",
      "   -> Selesai. Hasil MAPE: 3.3422%\n",
      "   ✓ Grafik disimpan: E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\\Grafik_Batch_64_Window_90.png\n",
      "   ✓ Excel disimpan: E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\\Prediksi_Batch_64_Window_90_Epoch_50.xlsx\n",
      "\n",
      "============================================================\n",
      "   Batch Size  Best Epoch (val)  Best Val Loss  Last Loss  Last Val Loss  \\\n",
      "0          16                46       0.000737   0.001218       0.001011   \n",
      "1          30                47       0.000808   0.001033       0.000959   \n",
      "2          64                49       0.000944   0.000899       0.000987   \n",
      "\n",
      "   MAPE (%)  \n",
      "0  5.541996  \n",
      "1  3.347179  \n",
      "2  3.342225  \n",
      "------------------------------------------------------------\n",
      "KESIMPULAN FINAL (KONFIGURASI MODEL TERBAIK):\n",
      "1. Normalisasi : YA (MinMaxScaler; fit di segmen TRAIN, transform 100% data)\n",
      "2. Window Size : 90\n",
      "3. Epoch       : 50\n",
      "4. Batch Size  : 64\n",
      "MAPE Terendah  : 3.3422%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#MENCARI KONFIGURASI batch_sizes TERBAIK SESUAI BAB 3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random as python_random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "\n",
    "def reset_seeds():\n",
    "    np.random.seed(42)\n",
    "    python_random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "reset_seeds()\n",
    "\n",
    "\n",
    "path_file_input = r\"E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Surabaya.xlsx\"\n",
    "path_output_folder = r\"E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\"\n",
    "os.makedirs(path_output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "if os.path.exists(path_file_input):\n",
    "    df = pd.read_excel(path_file_input)\n",
    "    \n",
    "    \n",
    "    nama_kolom_tanggal = 'Tanggal' \n",
    "    if nama_kolom_tanggal not in df.columns:\n",
    "        raise KeyError(f\"Kolom '{nama_kolom_tanggal}' tidak ditemukan di Excel!\")\n",
    "    \n",
    "    df[nama_kolom_tanggal] = pd.to_datetime(df[nama_kolom_tanggal])\n",
    "    print(\"✓ Data dan Tanggal berhasil dimuat.\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"File tidak ditemukan.\")\n",
    "\n",
    "raw_data = df['Harga (Rp)'].values.reshape(-1, 1)\n",
    "print(f\"✓ Jumlah baris asli (raw): {len(raw_data)}\") \n",
    "\n",
    "\n",
    "FIXED_WINDOW_SIZE = 90\n",
    "FIXED_EPOCH = 50\n",
    "scenario_batch_sizes = [16, 30, 64]\n",
    "VAL_RATIO = 0.1\n",
    "\n",
    "\n",
    "def create_sliding_window(dataset, window_size):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - window_size):\n",
    "        X.append(dataset[i:(i + window_size), 0])\n",
    "        Y.append(dataset[i + window_size, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def build_model_lstm(input_shape):\n",
    "    tf.random.set_seed(42)\n",
    "    model = Sequential()\n",
    "    # 2 LSTM layer\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.02))\n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(0.02))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "X_full_raw, Y_full_raw = create_sliding_window(raw_data, FIXED_WINDOW_SIZE)\n",
    "print(f\"✓ Jumlah sampel window: {len(X_full_raw)} (window={FIXED_WINDOW_SIZE})\") \n",
    "\n",
    "train_size = int(len(X_full_raw) * 0.8)\n",
    "y_test_orig = Y_full_raw[train_size:] \n",
    "\n",
    "\n",
    "all_dates = df[nama_kolom_tanggal].values[FIXED_WINDOW_SIZE:]\n",
    "test_dates = all_dates[train_size:] \n",
    "\n",
    "\n",
    "raw_train_segment = raw_data[:train_size + FIXED_WINDOW_SIZE]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(raw_train_segment)\n",
    "\n",
    "\n",
    "scaled_data = scaler.transform(raw_data)\n",
    "print(\"✓ Data ternormalisasi (0-1).\")\n",
    "\n",
    "\n",
    "X_full_scaled, Y_full_scaled = create_sliding_window(scaled_data, FIXED_WINDOW_SIZE)\n",
    "X_full_scaled = X_full_scaled.reshape(X_full_scaled.shape[0], X_full_scaled.shape[1], 1)\n",
    "\n",
    "\n",
    "X_train_all, X_test = X_full_scaled[:train_size], X_full_scaled[train_size:]\n",
    "y_train_all = Y_full_scaled[:train_size]\n",
    "\n",
    "\n",
    "val_cut = int(len(X_train_all) * (1 - VAL_RATIO))\n",
    "X_train, X_val = X_train_all[:val_cut], X_train_all[val_cut:]\n",
    "y_train, y_val = y_train_all[:val_cut], y_train_all[val_cut:]\n",
    "\n",
    "print(f\"\\n[Info] Dataset Window Size: {FIXED_WINDOW_SIZE}\")\n",
    "print(\"----------------------------------------\")\n",
    "print(f\"Total Window Samples: {len(X_full_scaled)} | Latih: {len(X_train_all)} | Uji: {len(X_test)}\")\n",
    "print(\"----------------------------------------\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MULAI FASE 2: SKENARIO C (Mencari Batch Size Terbaik)\")\n",
    "print(f\"Konfigurasi: Window {FIXED_WINDOW_SIZE} | Epoch {FIXED_EPOCH}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = []\n",
    "\n",
    "for batch_count in scenario_batch_sizes:\n",
    "    print(f\"\\n[Proses] Training dengan Batch Size: {batch_count} ...\")\n",
    "    reset_seeds()\n",
    "\n",
    "    model = build_model_lstm((X_train.shape[1], 1))\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=FIXED_EPOCH,\n",
    "        batch_size=batch_count,\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Ringkasan loss\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history.get('val_loss', None)\n",
    "    last_loss = float(train_loss[-1])\n",
    "    \n",
    "    if val_loss is not None:\n",
    "        last_val_loss = float(val_loss[-1])\n",
    "        best_epoch = int(np.argmin(val_loss) + 1)\n",
    "        best_val = float(np.min(val_loss))\n",
    "        print(f\"   -> Selesai epoch : {FIXED_EPOCH}\")\n",
    "        print(f\"   -> Best epoch    : {best_epoch} (val_loss={best_val:.6f})\")\n",
    "        print(f\"   -> Last loss     : {last_loss:.6f} | Last val_loss : {last_val_loss:.6f}\")\n",
    "    else:\n",
    "        best_epoch = int(np.argmin(train_loss) + 1)\n",
    "        best_tr = float(np.min(train_loss))\n",
    "        last_val_loss = None\n",
    "        best_val = None\n",
    "        print(f\"   -> Selesai epoch : {FIXED_EPOCH}\")\n",
    "        print(f\"   -> Best epoch    : {best_epoch} (loss={best_tr:.6f})\")\n",
    "        print(f\"   -> Last loss     : {last_loss:.6f}\")\n",
    "\n",
    "   \n",
    "    predictions_scaled = model.predict(X_test, verbose=1)\n",
    "    predictions_real = scaler.inverse_transform(predictions_scaled)\n",
    "\n",
    "    # MAPE terhadap data uji asli\n",
    "    mape = mean_absolute_percentage_error(y_test_orig, predictions_real) * 100\n",
    "    print(f\"   -> Selesai. Hasil MAPE: {mape:.4f}%\")\n",
    "\n",
    "    # Simpan ringkasan\n",
    "    results.append({\n",
    "        'Batch Size': batch_count,\n",
    "        'Best Epoch (val)': best_epoch,\n",
    "        'Best Val Loss': float(best_val) if val_loss is not None else None,\n",
    "        'Last Loss': last_loss,\n",
    "        'Last Val Loss': last_val_loss if val_loss is not None else None,\n",
    "        'MAPE (%)': float(mape)\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(12, 6)) \n",
    "    plt.plot(test_dates, y_test_orig, label='Actual (Real Data)')\n",
    "    plt.plot(test_dates, predictions_real, label='Predicted (Denormalized)')\n",
    "    \n",
    "    plt.title(f'Actual vs Predicted (Batch {batch_count}, Window {FIXED_WINDOW_SIZE}, Epoch {FIXED_EPOCH})')\n",
    "    plt.xlabel('Tanggal dan Tahun')\n",
    "    plt.ylabel('Harga (Rp)')\n",
    "    \n",
    "    # Format Tanggal\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    img_path = os.path.join(path_output_folder, f\"Grafik_Batch_{batch_count}_Window_{FIXED_WINDOW_SIZE}.png\")\n",
    "    plt.savefig(img_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"   ✓ Grafik disimpan: {img_path}\")\n",
    "\n",
    "\n",
    "    y_test_safe = np.where(y_test_orig.flatten() == 0, np.finfo(float).eps, y_test_orig.flatten())\n",
    "    err_pct = np.abs((y_test_orig.flatten() - predictions_real.flatten()) / y_test_safe) * 100\n",
    "\n",
    "    out_df = pd.DataFrame({\n",
    "        'Tanggal': test_dates, # <--- Kolom Baru\n",
    "        'Actual (Real)': y_test_orig.flatten(),\n",
    "        'Predicted (Real)': predictions_real.flatten(),\n",
    "        'Selisih': (y_test_orig.flatten() - predictions_real.flatten()),\n",
    "        'Error (%)': err_pct\n",
    "    })\n",
    "    out_path = os.path.join(path_output_folder, f\"Prediksi_Batch_{batch_count}_Window_{FIXED_WINDOW_SIZE}_Epoch_{FIXED_EPOCH}.xlsx\")\n",
    "    out_df.to_excel(out_path, index=False)\n",
    "    print(f\"   ✓ Excel disimpan: {out_path}\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "best_result = results_df.loc[results_df['MAPE (%)'].idxmin()]\n",
    "best_batch = int(best_result['Batch Size'])\n",
    "\n",
    "results_df.to_excel(os.path.join(path_output_folder, \"REKAP_MAPE_ALL_BATCHES.xlsx\"), index=False)\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"KESIMPULAN FINAL (KONFIGURASI MODEL TERBAIK):\")\n",
    "print(f\"1. Normalisasi : YA (MinMaxScaler; fit di segmen TRAIN, transform 100% data)\")\n",
    "print(f\"2. Window Size : {FIXED_WINDOW_SIZE}\")\n",
    "print(f\"3. Epoch       : {FIXED_EPOCH}\")\n",
    "print(f\"4. Batch Size  : {best_batch}\")\n",
    "print(f\"MAPE Terendah  : {best_result['MAPE (%)']:.4f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1ad77dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data: E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Surabaya.xlsx\n",
      "✓ Jumlah baris asli (raw): 1043\n",
      "✓ Sampel window: 953 (window=90)\n",
      "✓ Data ternormalisasi (0-1).\n",
      "[Info] Total: 953 | Train: 762 | Val: 77 | Test: 191\n",
      "   -> Selesai epoch : 50\n",
      "   -> Best epoch    : 49 (val_loss=0.000944)\n",
      "   -> Last loss     : 0.000899 | Last val_loss : 0.000987\n",
      "   -> MAPE          : 3.3422%\n",
      "   ✓ Plot disimpan: E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\\Surabaya_w90_e50_b64\\Surabaya_Plot.png\n",
      "   ✓ Prediksi disimpan: E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\\Surabaya_w90_e50_b64\\Surabaya_Prediksi_W90_E50_B64.xlsx\n",
      "   ✓ Ringkasan disimpan: E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\\Surabaya_w90_e50_b64\\Surabaya_Summary_W90_E50_B64.xlsx\n",
      "\n",
      "Selesai untuk file ini.\n"
     ]
    }
   ],
   "source": [
    "#UJI COBA KONFIG TERBAIK DIBAB 3 \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "\n",
    "def reset_seeds():\n",
    "    np.random.seed(42)\n",
    "    python_random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "reset_seeds()\n",
    "\n",
    "FIXED_WINDOW_SIZE = 90  \n",
    "FIXED_EPOCH = 50        \n",
    "FIXED_BATCH_SIZE = 64  \n",
    "VAL_RATIO = 0.1         \n",
    "\n",
    "\n",
    "path_file_input = r\"E:\\Skripsi\\Prediksi-bawang-merah\\python\\data\\data clean\\Data_Clean_Surabaya.xlsx\"\n",
    "path_output_folder = r\"E:\\SKRIPSI 2025\\dataset\\UJI COBA SESUAI DI BAB 3\"\n",
    "os.makedirs(path_output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "def create_sliding_window(dataset, window_size):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - window_size):\n",
    "        X.append(dataset[i:(i + window_size), 0])\n",
    "        Y.append(dataset[i + window_size, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def build_model_lstm(input_shape):\n",
    "    tf.random.set_seed(42)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.02)) \n",
    "    model.add(LSTM(100, return_sequences=False))\n",
    "    model.add(Dropout(0.02)) \n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "if not os.path.exists(path_file_input):\n",
    "    raise FileNotFoundError(f\"File tidak ditemukan: {path_file_input}\")\n",
    "\n",
    "df = pd.read_excel(path_file_input)\n",
    "\n",
    "\n",
    "nama_kolom_tanggal = 'Tanggal' \n",
    "if 'Harga (Rp)' not in df.columns:\n",
    "    raise KeyError(f\"Kolom 'Harga (Rp)' tidak ditemukan di file {path_file_input}\")\n",
    "\n",
    "\n",
    "df[nama_kolom_tanggal] = pd.to_datetime(df[nama_kolom_tanggal])\n",
    "# =============================\n",
    "\n",
    "raw_data = df['Harga (Rp)'].values.reshape(-1, 1)\n",
    "print(f\"✓ Data: {path_file_input}\")\n",
    "print(f\"✓ Jumlah baris asli (raw): {len(raw_data)}\")\n",
    "\n",
    "region_name = os.path.basename(path_file_input).replace(\"Data_Clean_\", \"\").replace(\".xlsx\", \"\")\n",
    "\n",
    "\n",
    "X_full_raw, Y_full_raw = create_sliding_window(raw_data, FIXED_WINDOW_SIZE)\n",
    "print(f\"✓ Sampel window: {len(X_full_raw)} (window={FIXED_WINDOW_SIZE})\")\n",
    "train_size = int(len(X_full_raw) * 0.8)\n",
    "y_test_orig = Y_full_raw[train_size:] \n",
    "\n",
    "raw_train_segment = raw_data[:train_size + FIXED_WINDOW_SIZE]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(raw_train_segment)\n",
    "scaled_data = scaler.transform(raw_data)\n",
    "print(\"✓ Data ternormalisasi (0-1).\")\n",
    "\n",
    "\n",
    "X_full_scaled, Y_full_scaled = create_sliding_window(scaled_data, FIXED_WINDOW_SIZE)\n",
    "X_full_scaled = X_full_scaled.reshape(X_full_scaled.shape[0], X_full_scaled.shape[1], 1)\n",
    "\n",
    "X_train_all, X_test = X_full_scaled[:train_size], X_full_scaled[train_size:]\n",
    "y_train_all = Y_full_scaled[:train_size]\n",
    "\n",
    "\n",
    "val_cut = int(len(X_train_all) * (1 - VAL_RATIO))\n",
    "X_train, X_val = X_train_all[:val_cut], X_train_all[val_cut:]\n",
    "y_train, y_val = y_train_all[:val_cut], y_train_all[val_cut:]\n",
    "\n",
    "print(f\"[Info] Total: {len(X_full_scaled)} | Train: {len(X_train_all)} | Val: {len(X_val)} | Test: {len(X_test)}\")\n",
    "\n",
    "\n",
    "reset_seeds()\n",
    "model = build_model_lstm((X_train.shape[1], 1))\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=FIXED_EPOCH,\n",
    "    batch_size=FIXED_BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=0,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history.get('val_loss', None)\n",
    "last_loss = float(train_loss[-1])\n",
    "last_val_loss = float(val_loss[-1]) if val_loss is not None else None\n",
    "best_epoch = int(np.argmin(val_loss) + 1) if val_loss is not None else int(np.argmin(train_loss) + 1)\n",
    "best_val = float(np.min(val_loss)) if val_loss is not None else float(np.min(train_loss))\n",
    "\n",
    "print(f\"   -> Selesai epoch : {FIXED_EPOCH}\")\n",
    "print(f\"   -> Best epoch    : {best_epoch} (val_loss={best_val:.6f})\")\n",
    "print(f\"   -> Last loss     : {last_loss:.6f}\" + (f\" | Last val_loss : {last_val_loss:.6f}\" if last_val_loss is not None else \"\"))\n",
    "\n",
    "\n",
    "predictions_scaled = model.predict(X_test, verbose=0)\n",
    "predictions_real = scaler.inverse_transform(predictions_scaled)\n",
    "mape = mean_absolute_percentage_error(y_test_orig.ravel(), predictions_real.ravel()) * 100\n",
    "print(f\"   -> MAPE          : {mape:.4f}%\")\n",
    "\n",
    "\n",
    "region_out_dir = os.path.join(path_output_folder, f\"{region_name}_w{FIXED_WINDOW_SIZE}_e{FIXED_EPOCH}_b{FIXED_BATCH_SIZE}\")\n",
    "os.makedirs(region_out_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "all_dates = df[nama_kolom_tanggal].values[FIXED_WINDOW_SIZE:]\n",
    "test_dates = all_dates[train_size:]\n",
    "# =======================================\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6)) \n",
    "plt.plot(test_dates, y_test_orig, label='Actual (Real Data)')\n",
    "plt.plot(test_dates, predictions_real, label='Predicted (Denormalized)')\n",
    "\n",
    "plt.title(f'{region_name} | W{FIXED_WINDOW_SIZE} E{FIXED_EPOCH} B{FIXED_BATCH_SIZE}')\n",
    "plt.xlabel('Tanggal dan Tahun') \n",
    "plt.ylabel('Harga (Rp)')\n",
    "\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "plt.gcf().autofmt_xdate()\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plot_path = os.path.join(region_out_dir, f\"{region_name}_Plot.png\")\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"   ✓ Plot disimpan: {plot_path}\")\n",
    "\n",
    "# Excel per-baris\n",
    "y_test_safe = np.where(y_test_orig.flatten() == 0, np.finfo(float).eps, y_test_orig.flatten())\n",
    "err_pct = np.abs((y_test_orig.flatten() - predictions_real.flatten()) / y_test_safe) * 100\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    "    'Tanggal': test_dates,\n",
    "    'Actual (Real)': y_test_orig.flatten(),\n",
    "    'Predicted (Real)': predictions_real.flatten(),\n",
    "    'Selisih': (y_test_orig.flatten() - predictions_real.flatten()),\n",
    "    'Error (%)': err_pct\n",
    "})\n",
    "# ==============================================\n",
    "\n",
    "excel_path = os.path.join(region_out_dir, f\"{region_name}_Prediksi_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "out_df.to_excel(excel_path, index=False)\n",
    "print(f\"   ✓ Prediksi disimpan: {excel_path}\")\n",
    "\n",
    "# Ringkasan singkat\n",
    "summary = pd.DataFrame([{\n",
    "    'Region': region_name,\n",
    "    'Window Size': int(FIXED_WINDOW_SIZE),\n",
    "    'Epoch': int(FIXED_EPOCH),\n",
    "    'Batch Size': int(FIXED_BATCH_SIZE),\n",
    "    'Best Epoch (val)': int(best_epoch),\n",
    "    'Best Val Loss': float(best_val),\n",
    "    'Last Loss': float(last_loss),\n",
    "    'Last Val Loss': float(last_val_loss) if last_val_loss is not None else None,\n",
    "    'MAPE (%)': float(mape)\n",
    "}])\n",
    "summary_path = os.path.join(region_out_dir, f\"{region_name}_Summary_W{FIXED_WINDOW_SIZE}_E{FIXED_EPOCH}_B{FIXED_BATCH_SIZE}.xlsx\")\n",
    "summary.to_excel(summary_path, index=False)\n",
    "print(f\"   ✓ Ringkasan disimpan: {summary_path}\")\n",
    "\n",
    "print(\"\\nSelesai untuk file ini.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
